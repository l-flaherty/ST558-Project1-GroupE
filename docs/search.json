[
  {
    "objectID": "ST558 Project 1 Quarto Doc.html",
    "href": "ST558 Project 1 Quarto Doc.html",
    "title": "ST558 Project 1",
    "section": "",
    "text": "We are interested in various types of census data, and aim to create functions that return visuals of said data from inputs of either urls or csv files. To start, we look at a single file before generalizing.\nThe file was made available at https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv. We could either download this locally and save it to our R session, accessing it through the working directory of our projects, or grab the data directly from the url. We opt for the latter. To start our analysis, we installed any packages we might need with install.packages, and call them here with library().\n\nlibrary(tidyverse)            \nlibrary(readxl)\n\nurl1 &lt;- \"https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv\"\ncensus &lt;- read_csv(url1)\ncensus\n\n# A tibble: 3,198 × 42\n   Area_name     STCOU EDU010187F EDU010187D EDU010187N1 EDU010187N2 EDU010188F\n   &lt;chr&gt;         &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;            &lt;dbl&gt;\n 1 UNITED STATES 00000          0   40024299 0000        0000                 0\n 2 ALABAMA       01000          0     733735 0000        0000                 0\n 3 Autauga, AL   01001          0       6829 0000        0000                 0\n 4 Baldwin, AL   01003          0      16417 0000        0000                 0\n 5 Barbour, AL   01005          0       5071 0000        0000                 0\n 6 Bibb, AL      01007          0       3557 0000        0000                 0\n 7 Blount, AL    01009          0       7319 0000        0000                 0\n 8 Bullock, AL   01011          0       2014 0000        0000                 0\n 9 Butler, AL    01013          0       4640 0000        0000                 0\n10 Calhoun, AL   01015          0      20939 0000        0000                 0\n# ℹ 3,188 more rows\n# ℹ 35 more variables: EDU010188D &lt;dbl&gt;, EDU010188N1 &lt;chr&gt;, EDU010188N2 &lt;chr&gt;,\n#   EDU010189F &lt;dbl&gt;, EDU010189D &lt;dbl&gt;, EDU010189N1 &lt;chr&gt;, EDU010189N2 &lt;chr&gt;,\n#   EDU010190F &lt;dbl&gt;, EDU010190D &lt;dbl&gt;, EDU010190N1 &lt;chr&gt;, EDU010190N2 &lt;chr&gt;,\n#   EDU010191F &lt;dbl&gt;, EDU010191D &lt;dbl&gt;, EDU010191N1 &lt;chr&gt;, EDU010191N2 &lt;chr&gt;,\n#   EDU010192F &lt;dbl&gt;, EDU010192D &lt;dbl&gt;, EDU010192N1 &lt;chr&gt;, EDU010192N2 &lt;chr&gt;,\n#   EDU010193F &lt;dbl&gt;, EDU010193D &lt;dbl&gt;, EDU010193N1 &lt;chr&gt;, EDU010193N2 &lt;chr&gt;, …\n\n\n\n\nTo get an initial glance at the data, we try normal summary functions. Since the output of these functions is so long, we admit it here. What is clear from the output is that without additional context for what the variables mean, the file contents would be very confusing.\n\nstr(census)\nsummary(census)\n\nLuckily we are given some of this information. The file contains census data from 2010, with distinct areas in each row, and census surveys in each column. The census surveys follow a code: the first three characters give the survey type (for example AGE in the AGE010180D code refers to age, while EDU in the EDU640180D code refers to education), the next four give the type of value from the survey (for example 6401 in the EDU640180D code refers to years of school complete, while 0101 in the EDU010189D code refers to public school enrollment), and the next two give the year (for example the 89 in the EDU010189D code refers to 1989). There is no data from before 1910.\n\n\n\n\n\nAs is, the data is not in a great format for analysis. We want to filter down the data to just the columns we actually care about, and to put it in long format. That is, instead of a distinct area in each row with many different census types in the columns, we want to have just one record for each row, with an additional column added for the census code.\nTo choose the columns we want, ew use the select() function from the tidyverse. To keep our naming conventions consistent, we also want to rename() certain columns. Additionally, we want to transform our data structure so that the columns holding count data are put in a single column, and the data from those columns put in a new column called observed. We can do so with the pivot_longer() function. Putting all these steps together with the natural chaining operation |&gt;, we can overwrite our object as follows:\n\ncensus &lt;- census |&gt;                   \n  select(Area_name, STCOU, ends_with(\"D\")) |&gt;\n  rename(area_name=Area_name) |&gt;\n  pivot_longer(cols=ends_with(\"D\"),\n               names_to=\"code\",    \n               values_to=\"observed\")\n\ncensus\n\n# A tibble: 31,980 × 4\n   area_name     STCOU code       observed\n   &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1 UNITED STATES 00000 EDU010187D 40024299\n 2 UNITED STATES 00000 EDU010188D 39967624\n 3 UNITED STATES 00000 EDU010189D 40317775\n 4 UNITED STATES 00000 EDU010190D 40737600\n 5 UNITED STATES 00000 EDU010191D 41385442\n 6 UNITED STATES 00000 EDU010192D 42088151\n 7 UNITED STATES 00000 EDU010193D 42724710\n 8 UNITED STATES 00000 EDU010194D 43369917\n 9 UNITED STATES 00000 EDU010195D 43993459\n10 UNITED STATES 00000 EDU010196D 44715737\n# ℹ 31,970 more rows\n\n\n\n\n\nIn general, we want the smallest piece of data stored in it’s own column. Specific to this file, the census code encodes a lot of information which we’d like to break up so that we can more easily filter it in the future.\nOne way to do so is to extract the year from which the survey was conducted on, and store the year and census type in their own columns. Note that direct inspection on a csv file giving information on the variables. Therefor, we parse the string to pull out the year and convert the year into a numeric value such as 1997 or 2002. We then grab the first three characters and following four digits to create a new variable representing which measurement was grabbed using substr() function from baseR.\n\ncensus &lt;- census |&gt;\n  mutate(survey_type = substr(census$code, 1, 7), \n         survey_year = substr(census$code, 8, 9)) |&gt;\n  select(area_name, STCOU, code, survey_type, survey_year, observed)\n\ncensus$survey_year &lt;- year(parse_date_time(census$survey_year, \"y\"))\n\ncensus\n\n# A tibble: 31,980 × 6\n   area_name     STCOU code       survey_type survey_year observed\n   &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n 1 UNITED STATES 00000 EDU010187D EDU0101            1987 40024299\n 2 UNITED STATES 00000 EDU010188D EDU0101            1988 39967624\n 3 UNITED STATES 00000 EDU010189D EDU0101            1989 40317775\n 4 UNITED STATES 00000 EDU010190D EDU0101            1990 40737600\n 5 UNITED STATES 00000 EDU010191D EDU0101            1991 41385442\n 6 UNITED STATES 00000 EDU010192D EDU0101            1992 42088151\n 7 UNITED STATES 00000 EDU010193D EDU0101            1993 42724710\n 8 UNITED STATES 00000 EDU010194D EDU0101            1994 43369917\n 9 UNITED STATES 00000 EDU010195D EDU0101            1995 43993459\n10 UNITED STATES 00000 EDU010196D EDU0101            1996 44715737\n# ℹ 31,970 more rows\n\n\n\n\n\nIn keeping with the above, we’d like to get more granular into our data, specifying the county name when available. To do so, we again rely on the stringr package and perform similar operations to the above.\nWe first get a sense of the naming patters in our area_name column.\n\nunique(census$area_name)[1:10]\n\n [1] \"UNITED STATES\" \"ALABAMA\"       \"Autauga, AL\"   \"Baldwin, AL\"  \n [5] \"Barbour, AL\"   \"Bibb, AL\"      \"Blount, AL\"    \"Bullock, AL\"  \n [9] \"Butler, AL\"    \"Calhoun, AL\"  \n\n\nNotice that commas exist in areas which have the county specified (like “Autauga, AL”), but there are no commas in areas without county-level data (like “ALABAMA”). We can split our existing census tibble into two different tibbles, one with county-level data and one without, by searching for the rows in the tibble which have a comma. The str_locate() function in the stringr package does the trick, taking in our vector of area_name’s, searching for the comma, and returning a matrix giving the starting and ending character of where the comma exists. Since a comma is only one character, we only need one of these columns, and so return just the first column from our matrix.\n\n#dummy object, no commas in non-county\na &lt;- str_locate(census$area_name, \",\")[,1]\n#keep non-county data together\nnoncounty &lt;- census[which(is.na(a)),]\n#keep county data together\ncounty &lt;- census[which(!is.na(a)),]\n#no need to keep\nrm(a)\n\nnoncounty\n\n# A tibble: 530 × 6\n   area_name     STCOU code       survey_type survey_year observed\n   &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n 1 UNITED STATES 00000 EDU010187D EDU0101            1987 40024299\n 2 UNITED STATES 00000 EDU010188D EDU0101            1988 39967624\n 3 UNITED STATES 00000 EDU010189D EDU0101            1989 40317775\n 4 UNITED STATES 00000 EDU010190D EDU0101            1990 40737600\n 5 UNITED STATES 00000 EDU010191D EDU0101            1991 41385442\n 6 UNITED STATES 00000 EDU010192D EDU0101            1992 42088151\n 7 UNITED STATES 00000 EDU010193D EDU0101            1993 42724710\n 8 UNITED STATES 00000 EDU010194D EDU0101            1994 43369917\n 9 UNITED STATES 00000 EDU010195D EDU0101            1995 43993459\n10 UNITED STATES 00000 EDU010196D EDU0101            1996 44715737\n# ℹ 520 more rows\n\ncounty\n\n# A tibble: 31,450 × 6\n   area_name   STCOU code       survey_type survey_year observed\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n 1 Autauga, AL 01001 EDU010187D EDU0101            1987     6829\n 2 Autauga, AL 01001 EDU010188D EDU0101            1988     6900\n 3 Autauga, AL 01001 EDU010189D EDU0101            1989     6920\n 4 Autauga, AL 01001 EDU010190D EDU0101            1990     6847\n 5 Autauga, AL 01001 EDU010191D EDU0101            1991     7008\n 6 Autauga, AL 01001 EDU010192D EDU0101            1992     7137\n 7 Autauga, AL 01001 EDU010193D EDU0101            1993     7152\n 8 Autauga, AL 01001 EDU010194D EDU0101            1994     7381\n 9 Autauga, AL 01001 EDU010195D EDU0101            1995     7568\n10 Autauga, AL 01001 EDU010196D EDU0101            1996     7834\n# ℹ 31,440 more rows\n\n\nWe can double check that this split worked as expected with unique from base R.\n\nunique(noncounty$area_name)                        \n\n [1] \"UNITED STATES\"        \"ALABAMA\"              \"ALASKA\"              \n [4] \"ARIZONA\"              \"ARKANSAS\"             \"CALIFORNIA\"          \n [7] \"COLORADO\"             \"CONNECTICUT\"          \"DELAWARE\"            \n[10] \"DISTRICT OF COLUMBIA\" \"District of Columbia\" \"FLORIDA\"             \n[13] \"GEORGIA\"              \"HAWAII\"               \"IDAHO\"               \n[16] \"ILLINOIS\"             \"INDIANA\"              \"IOWA\"                \n[19] \"KANSAS\"               \"KENTUCKY\"             \"LOUISIANA\"           \n[22] \"MAINE\"                \"MARYLAND\"             \"MASSACHUSETTS\"       \n[25] \"MICHIGAN\"             \"MINNESOTA\"            \"MISSISSIPPI\"         \n[28] \"MISSOURI\"             \"MONTANA\"              \"NEBRASKA\"            \n[31] \"NEVADA\"               \"NEW HAMPSHIRE\"        \"NEW JERSEY\"          \n[34] \"NEW MEXICO\"           \"NEW YORK\"             \"NORTH CAROLINA\"      \n[37] \"NORTH DAKOTA\"         \"OHIO\"                 \"OKLAHOMA\"            \n[40] \"OREGON\"               \"PENNSYLVANIA\"         \"RHODE ISLAND\"        \n[43] \"SOUTH CAROLINA\"       \"SOUTH DAKOTA\"         \"TENNESSEE\"           \n[46] \"TEXAS\"                \"UTAH\"                 \"VERMONT\"             \n[49] \"VIRGINIA\"             \"WASHINGTON\"           \"WEST VIRGINIA\"       \n[52] \"WISCONSIN\"            \"WYOMING\"             \n\nunique(county$area_name)[1:50]\n\n [1] \"Autauga, AL\"    \"Baldwin, AL\"    \"Barbour, AL\"    \"Bibb, AL\"      \n [5] \"Blount, AL\"     \"Bullock, AL\"    \"Butler, AL\"     \"Calhoun, AL\"   \n [9] \"Chambers, AL\"   \"Cherokee, AL\"   \"Chilton, AL\"    \"Choctaw, AL\"   \n[13] \"Clarke, AL\"     \"Clay, AL\"       \"Cleburne, AL\"   \"Coffee, AL\"    \n[17] \"Colbert, AL\"    \"Conecuh, AL\"    \"Coosa, AL\"      \"Covington, AL\" \n[21] \"Crenshaw, AL\"   \"Cullman, AL\"    \"Dale, AL\"       \"Dallas, AL\"    \n[25] \"DeKalb, AL\"     \"Elmore, AL\"     \"Escambia, AL\"   \"Etowah, AL\"    \n[29] \"Fayette, AL\"    \"Franklin, AL\"   \"Geneva, AL\"     \"Greene, AL\"    \n[33] \"Hale, AL\"       \"Henry, AL\"      \"Houston, AL\"    \"Jackson, AL\"   \n[37] \"Jefferson, AL\"  \"Lamar, AL\"      \"Lauderdale, AL\" \"Lawrence, AL\"  \n[41] \"Lee, AL\"        \"Limestone, AL\"  \"Lowndes, AL\"    \"Macon, AL\"     \n[45] \"Madison, AL\"    \"Marengo, AL\"    \"Marion, AL\"     \"Marshall, AL\"  \n[49] \"Mobile, AL\"     \"Monroe, AL\"    \n\n\nAfter verifying that the split worked as intended, we add a class to each tibble, overwriting the previous one.\n\nclass(county) &lt;- c(\"county\", class(county))           \nclass(noncounty) &lt;- c(\"state\", class(noncounty))\n\nclass(county)\n\n[1] \"county\"     \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nclass(noncounty)\n\n[1] \"state\"      \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n\n\nWith the distinct tables now in hand, we want to break up the area_name to both the county and state in the case of the county data, and to include the division in the case of the noncounty data.\nIn the county data, we are just extracting the last two characters of the string for the state abbreviation, and all parts of the string less the last four for the county (two for the state abbreviation, one for the space, one for the comma). We can do this succinctly with the same str_sub function, utilizing the nchar function in the process (which logically returns the number of characters a string has).\n\ncounty &lt;- county |&gt;\n  mutate(state=str_sub(area_name, nchar(county$area_name) - 1, nchar(county$area_name)),\n         district=str_sub(area_name, 1, nchar(county$area_name)-4)) |&gt;\n  select(area_name, state, district, everything())\n\ncounty\n\n# A tibble: 31,450 × 8\n   area_name   state district STCOU code       survey_type survey_year observed\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n 1 Autauga, AL AL    Autauga  01001 EDU010187D EDU0101            1987     6829\n 2 Autauga, AL AL    Autauga  01001 EDU010188D EDU0101            1988     6900\n 3 Autauga, AL AL    Autauga  01001 EDU010189D EDU0101            1989     6920\n 4 Autauga, AL AL    Autauga  01001 EDU010190D EDU0101            1990     6847\n 5 Autauga, AL AL    Autauga  01001 EDU010191D EDU0101            1991     7008\n 6 Autauga, AL AL    Autauga  01001 EDU010192D EDU0101            1992     7137\n 7 Autauga, AL AL    Autauga  01001 EDU010193D EDU0101            1993     7152\n 8 Autauga, AL AL    Autauga  01001 EDU010194D EDU0101            1994     7381\n 9 Autauga, AL AL    Autauga  01001 EDU010195D EDU0101            1995     7568\n10 Autauga, AL AL    Autauga  01001 EDU010196D EDU0101            1996     7834\n# ℹ 31,440 more rows\n\n\n\n\n\nIn the noncounty data, we are adding a variable corresponding to the state’s classification of divisions found at https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States?useskin=vector. We store these classifications in a list called region. Note that the syntax of the strings in our list was choosen to follow the syntax of the names which exist in our noncounty$area_name.\n\nd1 &lt;- c(\"CONNECTICUT\", \"MAINE\", \"MASSACHUSETTS\", \"NEW HAMPSHIRE\", \"RHODE ISLAND\", \"VERMONT\")\nd2 &lt;- c(\"NEW JERSEY\", \"NEW YORK\", \"PENNSYLVANIA\")\nd3 &lt;- c(\"ILLINOIS\", \"INDIANA\", \"MICHIGAN\", \"OHIO\", \"WISCONSIN\")\nd4 &lt;- c(\"IOWA\", \"KANSAS\", \"MINNESOTA\", \"MISSOURI\", \"NEBRASKA\", \"NORTH DAKOTA\", \"SOUTH DAKOTA\")\nd5 &lt;- c(\"DELAWARE\", \"FLORIDA\", \"GEORGIA\", \"MARYLAND\", \"NORTH CAROLINA\", \"SOUTH CAROLINA\", \"VIRGINIA\", \"DISTRICT OF COLUMBIA\", \"District of Columbia\", \"WEST VIRGINIA\")\nd6 &lt;- c(\"ALABAMA\", \"KENTUCKY\", \"MISSISSIPPI\", \"TENNESSEE\")\nd7 &lt;- c(\"ARKANSAS\", \"LOUISIANA\", \"OKLAHOMA\", \"TEXAS\")\nd8 &lt;- c(\"ARIZONA\", \"COLORADO\", \"IDAHO\", \"MONTANA\", \"NEVADA\", \"NEW MEXICO\", \"UTAH\", \"WYOMING\")\nd9 &lt;- c(\"ALASKA\", \"CALIFORNIA\", \"HAWAII\", \"OREGON\", \"WASHINGTON\")\n\nregion &lt;- list(d1,d2,d3,d4,d5,d6,d7,d8,d9)\n\nNext we initialize the division vector we want to add, and create a for loop to find it’s values. The strategy in the loop is to look at each row of our noncounty data, then cycle through each element of the region list to find which column contains the state we are looking for. To do so, we utilize a while loop, only iterating to the next list element if our area_name wasn’t in the previous list element (hence the use of the negation operator). Note the use of [[]] as opposed to []– we use the %in% function to check whether our row’s area_name is in a vector.\n\ndivision &lt;- vector()\n\nfor (i in 1:nrow(noncounty)) {\n  j=1\n  while(j&lt;=length(region) && !(noncounty$area_name[i] %in% region[[j]])) {\n    j=j+1\n  }\n  division[i] &lt;- ifelse(j&lt;=length(region), j, \"ERROR\")\n}\n\nnoncounty$division &lt;- division\nnoncounty &lt;- noncounty |&gt; select(area_name, division, everything())\n\n#keep environment clean\nrm(d1,d2,d3,d4,d5,d6,d7,d8,d9,region,division,i,j)\n\nnoncounty\n\n# A tibble: 530 × 7\n   area_name     division STCOU code       survey_type survey_year observed\n   &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n 1 UNITED STATES ERROR    00000 EDU010187D EDU0101            1987 40024299\n 2 UNITED STATES ERROR    00000 EDU010188D EDU0101            1988 39967624\n 3 UNITED STATES ERROR    00000 EDU010189D EDU0101            1989 40317775\n 4 UNITED STATES ERROR    00000 EDU010190D EDU0101            1990 40737600\n 5 UNITED STATES ERROR    00000 EDU010191D EDU0101            1991 41385442\n 6 UNITED STATES ERROR    00000 EDU010192D EDU0101            1992 42088151\n 7 UNITED STATES ERROR    00000 EDU010193D EDU0101            1993 42724710\n 8 UNITED STATES ERROR    00000 EDU010194D EDU0101            1994 43369917\n 9 UNITED STATES ERROR    00000 EDU010195D EDU0101            1995 43993459\n10 UNITED STATES ERROR    00000 EDU010196D EDU0101            1996 44715737\n# ℹ 520 more rows"
  },
  {
    "objectID": "ST558 Project 1 Quarto Doc.html#data-processing",
    "href": "ST558 Project 1 Quarto Doc.html#data-processing",
    "title": "ST558 Project 1",
    "section": "",
    "text": "We are interested in various types of census data, and aim to create functions that return visuals of said data from inputs of either urls or csv files. To start, we look at a single file before generalizing.\nThe file was made available at https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv. We could either download this locally and save it to our R session, accessing it through the working directory of our projects, or grab the data directly from the url. We opt for the latter. To start our analysis, we installed any packages we might need with install.packages, and call them here with library().\n\nlibrary(tidyverse)            \nlibrary(readxl)\n\nurl1 &lt;- \"https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv\"\ncensus &lt;- read_csv(url1)\ncensus\n\n# A tibble: 3,198 × 42\n   Area_name     STCOU EDU010187F EDU010187D EDU010187N1 EDU010187N2 EDU010188F\n   &lt;chr&gt;         &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;            &lt;dbl&gt;\n 1 UNITED STATES 00000          0   40024299 0000        0000                 0\n 2 ALABAMA       01000          0     733735 0000        0000                 0\n 3 Autauga, AL   01001          0       6829 0000        0000                 0\n 4 Baldwin, AL   01003          0      16417 0000        0000                 0\n 5 Barbour, AL   01005          0       5071 0000        0000                 0\n 6 Bibb, AL      01007          0       3557 0000        0000                 0\n 7 Blount, AL    01009          0       7319 0000        0000                 0\n 8 Bullock, AL   01011          0       2014 0000        0000                 0\n 9 Butler, AL    01013          0       4640 0000        0000                 0\n10 Calhoun, AL   01015          0      20939 0000        0000                 0\n# ℹ 3,188 more rows\n# ℹ 35 more variables: EDU010188D &lt;dbl&gt;, EDU010188N1 &lt;chr&gt;, EDU010188N2 &lt;chr&gt;,\n#   EDU010189F &lt;dbl&gt;, EDU010189D &lt;dbl&gt;, EDU010189N1 &lt;chr&gt;, EDU010189N2 &lt;chr&gt;,\n#   EDU010190F &lt;dbl&gt;, EDU010190D &lt;dbl&gt;, EDU010190N1 &lt;chr&gt;, EDU010190N2 &lt;chr&gt;,\n#   EDU010191F &lt;dbl&gt;, EDU010191D &lt;dbl&gt;, EDU010191N1 &lt;chr&gt;, EDU010191N2 &lt;chr&gt;,\n#   EDU010192F &lt;dbl&gt;, EDU010192D &lt;dbl&gt;, EDU010192N1 &lt;chr&gt;, EDU010192N2 &lt;chr&gt;,\n#   EDU010193F &lt;dbl&gt;, EDU010193D &lt;dbl&gt;, EDU010193N1 &lt;chr&gt;, EDU010193N2 &lt;chr&gt;, …\n\n\n\n\nTo get an initial glance at the data, we try normal summary functions. Since the output of these functions is so long, we admit it here. What is clear from the output is that without additional context for what the variables mean, the file contents would be very confusing.\n\nstr(census)\nsummary(census)\n\nLuckily we are given some of this information. The file contains census data from 2010, with distinct areas in each row, and census surveys in each column. The census surveys follow a code: the first three characters give the survey type (for example AGE in the AGE010180D code refers to age, while EDU in the EDU640180D code refers to education), the next four give the type of value from the survey (for example 6401 in the EDU640180D code refers to years of school complete, while 0101 in the EDU010189D code refers to public school enrollment), and the next two give the year (for example the 89 in the EDU010189D code refers to 1989). There is no data from before 1910.\n\n\n\n\n\nAs is, the data is not in a great format for analysis. We want to filter down the data to just the columns we actually care about, and to put it in long format. That is, instead of a distinct area in each row with many different census types in the columns, we want to have just one record for each row, with an additional column added for the census code.\nTo choose the columns we want, ew use the select() function from the tidyverse. To keep our naming conventions consistent, we also want to rename() certain columns. Additionally, we want to transform our data structure so that the columns holding count data are put in a single column, and the data from those columns put in a new column called observed. We can do so with the pivot_longer() function. Putting all these steps together with the natural chaining operation |&gt;, we can overwrite our object as follows:\n\ncensus &lt;- census |&gt;                   \n  select(Area_name, STCOU, ends_with(\"D\")) |&gt;\n  rename(area_name=Area_name) |&gt;\n  pivot_longer(cols=ends_with(\"D\"),\n               names_to=\"code\",    \n               values_to=\"observed\")\n\ncensus\n\n# A tibble: 31,980 × 4\n   area_name     STCOU code       observed\n   &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1 UNITED STATES 00000 EDU010187D 40024299\n 2 UNITED STATES 00000 EDU010188D 39967624\n 3 UNITED STATES 00000 EDU010189D 40317775\n 4 UNITED STATES 00000 EDU010190D 40737600\n 5 UNITED STATES 00000 EDU010191D 41385442\n 6 UNITED STATES 00000 EDU010192D 42088151\n 7 UNITED STATES 00000 EDU010193D 42724710\n 8 UNITED STATES 00000 EDU010194D 43369917\n 9 UNITED STATES 00000 EDU010195D 43993459\n10 UNITED STATES 00000 EDU010196D 44715737\n# ℹ 31,970 more rows\n\n\n\n\n\nIn general, we want the smallest piece of data stored in it’s own column. Specific to this file, the census code encodes a lot of information which we’d like to break up so that we can more easily filter it in the future.\nOne way to do so is to extract the year from which the survey was conducted on, and store the year and census type in their own columns. Note that direct inspection on a csv file giving information on the variables. Therefor, we parse the string to pull out the year and convert the year into a numeric value such as 1997 or 2002. We then grab the first three characters and following four digits to create a new variable representing which measurement was grabbed using substr() function from baseR.\n\ncensus &lt;- census |&gt;\n  mutate(survey_type = substr(census$code, 1, 7), \n         survey_year = substr(census$code, 8, 9)) |&gt;\n  select(area_name, STCOU, code, survey_type, survey_year, observed)\n\ncensus$survey_year &lt;- year(parse_date_time(census$survey_year, \"y\"))\n\ncensus\n\n# A tibble: 31,980 × 6\n   area_name     STCOU code       survey_type survey_year observed\n   &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n 1 UNITED STATES 00000 EDU010187D EDU0101            1987 40024299\n 2 UNITED STATES 00000 EDU010188D EDU0101            1988 39967624\n 3 UNITED STATES 00000 EDU010189D EDU0101            1989 40317775\n 4 UNITED STATES 00000 EDU010190D EDU0101            1990 40737600\n 5 UNITED STATES 00000 EDU010191D EDU0101            1991 41385442\n 6 UNITED STATES 00000 EDU010192D EDU0101            1992 42088151\n 7 UNITED STATES 00000 EDU010193D EDU0101            1993 42724710\n 8 UNITED STATES 00000 EDU010194D EDU0101            1994 43369917\n 9 UNITED STATES 00000 EDU010195D EDU0101            1995 43993459\n10 UNITED STATES 00000 EDU010196D EDU0101            1996 44715737\n# ℹ 31,970 more rows\n\n\n\n\n\nIn keeping with the above, we’d like to get more granular into our data, specifying the county name when available. To do so, we again rely on the stringr package and perform similar operations to the above.\nWe first get a sense of the naming patters in our area_name column.\n\nunique(census$area_name)[1:10]\n\n [1] \"UNITED STATES\" \"ALABAMA\"       \"Autauga, AL\"   \"Baldwin, AL\"  \n [5] \"Barbour, AL\"   \"Bibb, AL\"      \"Blount, AL\"    \"Bullock, AL\"  \n [9] \"Butler, AL\"    \"Calhoun, AL\"  \n\n\nNotice that commas exist in areas which have the county specified (like “Autauga, AL”), but there are no commas in areas without county-level data (like “ALABAMA”). We can split our existing census tibble into two different tibbles, one with county-level data and one without, by searching for the rows in the tibble which have a comma. The str_locate() function in the stringr package does the trick, taking in our vector of area_name’s, searching for the comma, and returning a matrix giving the starting and ending character of where the comma exists. Since a comma is only one character, we only need one of these columns, and so return just the first column from our matrix.\n\n#dummy object, no commas in non-county\na &lt;- str_locate(census$area_name, \",\")[,1]\n#keep non-county data together\nnoncounty &lt;- census[which(is.na(a)),]\n#keep county data together\ncounty &lt;- census[which(!is.na(a)),]\n#no need to keep\nrm(a)\n\nnoncounty\n\n# A tibble: 530 × 6\n   area_name     STCOU code       survey_type survey_year observed\n   &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n 1 UNITED STATES 00000 EDU010187D EDU0101            1987 40024299\n 2 UNITED STATES 00000 EDU010188D EDU0101            1988 39967624\n 3 UNITED STATES 00000 EDU010189D EDU0101            1989 40317775\n 4 UNITED STATES 00000 EDU010190D EDU0101            1990 40737600\n 5 UNITED STATES 00000 EDU010191D EDU0101            1991 41385442\n 6 UNITED STATES 00000 EDU010192D EDU0101            1992 42088151\n 7 UNITED STATES 00000 EDU010193D EDU0101            1993 42724710\n 8 UNITED STATES 00000 EDU010194D EDU0101            1994 43369917\n 9 UNITED STATES 00000 EDU010195D EDU0101            1995 43993459\n10 UNITED STATES 00000 EDU010196D EDU0101            1996 44715737\n# ℹ 520 more rows\n\ncounty\n\n# A tibble: 31,450 × 6\n   area_name   STCOU code       survey_type survey_year observed\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n 1 Autauga, AL 01001 EDU010187D EDU0101            1987     6829\n 2 Autauga, AL 01001 EDU010188D EDU0101            1988     6900\n 3 Autauga, AL 01001 EDU010189D EDU0101            1989     6920\n 4 Autauga, AL 01001 EDU010190D EDU0101            1990     6847\n 5 Autauga, AL 01001 EDU010191D EDU0101            1991     7008\n 6 Autauga, AL 01001 EDU010192D EDU0101            1992     7137\n 7 Autauga, AL 01001 EDU010193D EDU0101            1993     7152\n 8 Autauga, AL 01001 EDU010194D EDU0101            1994     7381\n 9 Autauga, AL 01001 EDU010195D EDU0101            1995     7568\n10 Autauga, AL 01001 EDU010196D EDU0101            1996     7834\n# ℹ 31,440 more rows\n\n\nWe can double check that this split worked as expected with unique from base R.\n\nunique(noncounty$area_name)                        \n\n [1] \"UNITED STATES\"        \"ALABAMA\"              \"ALASKA\"              \n [4] \"ARIZONA\"              \"ARKANSAS\"             \"CALIFORNIA\"          \n [7] \"COLORADO\"             \"CONNECTICUT\"          \"DELAWARE\"            \n[10] \"DISTRICT OF COLUMBIA\" \"District of Columbia\" \"FLORIDA\"             \n[13] \"GEORGIA\"              \"HAWAII\"               \"IDAHO\"               \n[16] \"ILLINOIS\"             \"INDIANA\"              \"IOWA\"                \n[19] \"KANSAS\"               \"KENTUCKY\"             \"LOUISIANA\"           \n[22] \"MAINE\"                \"MARYLAND\"             \"MASSACHUSETTS\"       \n[25] \"MICHIGAN\"             \"MINNESOTA\"            \"MISSISSIPPI\"         \n[28] \"MISSOURI\"             \"MONTANA\"              \"NEBRASKA\"            \n[31] \"NEVADA\"               \"NEW HAMPSHIRE\"        \"NEW JERSEY\"          \n[34] \"NEW MEXICO\"           \"NEW YORK\"             \"NORTH CAROLINA\"      \n[37] \"NORTH DAKOTA\"         \"OHIO\"                 \"OKLAHOMA\"            \n[40] \"OREGON\"               \"PENNSYLVANIA\"         \"RHODE ISLAND\"        \n[43] \"SOUTH CAROLINA\"       \"SOUTH DAKOTA\"         \"TENNESSEE\"           \n[46] \"TEXAS\"                \"UTAH\"                 \"VERMONT\"             \n[49] \"VIRGINIA\"             \"WASHINGTON\"           \"WEST VIRGINIA\"       \n[52] \"WISCONSIN\"            \"WYOMING\"             \n\nunique(county$area_name)[1:50]\n\n [1] \"Autauga, AL\"    \"Baldwin, AL\"    \"Barbour, AL\"    \"Bibb, AL\"      \n [5] \"Blount, AL\"     \"Bullock, AL\"    \"Butler, AL\"     \"Calhoun, AL\"   \n [9] \"Chambers, AL\"   \"Cherokee, AL\"   \"Chilton, AL\"    \"Choctaw, AL\"   \n[13] \"Clarke, AL\"     \"Clay, AL\"       \"Cleburne, AL\"   \"Coffee, AL\"    \n[17] \"Colbert, AL\"    \"Conecuh, AL\"    \"Coosa, AL\"      \"Covington, AL\" \n[21] \"Crenshaw, AL\"   \"Cullman, AL\"    \"Dale, AL\"       \"Dallas, AL\"    \n[25] \"DeKalb, AL\"     \"Elmore, AL\"     \"Escambia, AL\"   \"Etowah, AL\"    \n[29] \"Fayette, AL\"    \"Franklin, AL\"   \"Geneva, AL\"     \"Greene, AL\"    \n[33] \"Hale, AL\"       \"Henry, AL\"      \"Houston, AL\"    \"Jackson, AL\"   \n[37] \"Jefferson, AL\"  \"Lamar, AL\"      \"Lauderdale, AL\" \"Lawrence, AL\"  \n[41] \"Lee, AL\"        \"Limestone, AL\"  \"Lowndes, AL\"    \"Macon, AL\"     \n[45] \"Madison, AL\"    \"Marengo, AL\"    \"Marion, AL\"     \"Marshall, AL\"  \n[49] \"Mobile, AL\"     \"Monroe, AL\"    \n\n\nAfter verifying that the split worked as intended, we add a class to each tibble, overwriting the previous one.\n\nclass(county) &lt;- c(\"county\", class(county))           \nclass(noncounty) &lt;- c(\"state\", class(noncounty))\n\nclass(county)\n\n[1] \"county\"     \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nclass(noncounty)\n\n[1] \"state\"      \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n\n\nWith the distinct tables now in hand, we want to break up the area_name to both the county and state in the case of the county data, and to include the division in the case of the noncounty data.\nIn the county data, we are just extracting the last two characters of the string for the state abbreviation, and all parts of the string less the last four for the county (two for the state abbreviation, one for the space, one for the comma). We can do this succinctly with the same str_sub function, utilizing the nchar function in the process (which logically returns the number of characters a string has).\n\ncounty &lt;- county |&gt;\n  mutate(state=str_sub(area_name, nchar(county$area_name) - 1, nchar(county$area_name)),\n         district=str_sub(area_name, 1, nchar(county$area_name)-4)) |&gt;\n  select(area_name, state, district, everything())\n\ncounty\n\n# A tibble: 31,450 × 8\n   area_name   state district STCOU code       survey_type survey_year observed\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n 1 Autauga, AL AL    Autauga  01001 EDU010187D EDU0101            1987     6829\n 2 Autauga, AL AL    Autauga  01001 EDU010188D EDU0101            1988     6900\n 3 Autauga, AL AL    Autauga  01001 EDU010189D EDU0101            1989     6920\n 4 Autauga, AL AL    Autauga  01001 EDU010190D EDU0101            1990     6847\n 5 Autauga, AL AL    Autauga  01001 EDU010191D EDU0101            1991     7008\n 6 Autauga, AL AL    Autauga  01001 EDU010192D EDU0101            1992     7137\n 7 Autauga, AL AL    Autauga  01001 EDU010193D EDU0101            1993     7152\n 8 Autauga, AL AL    Autauga  01001 EDU010194D EDU0101            1994     7381\n 9 Autauga, AL AL    Autauga  01001 EDU010195D EDU0101            1995     7568\n10 Autauga, AL AL    Autauga  01001 EDU010196D EDU0101            1996     7834\n# ℹ 31,440 more rows\n\n\n\n\n\nIn the noncounty data, we are adding a variable corresponding to the state’s classification of divisions found at https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States?useskin=vector. We store these classifications in a list called region. Note that the syntax of the strings in our list was choosen to follow the syntax of the names which exist in our noncounty$area_name.\n\nd1 &lt;- c(\"CONNECTICUT\", \"MAINE\", \"MASSACHUSETTS\", \"NEW HAMPSHIRE\", \"RHODE ISLAND\", \"VERMONT\")\nd2 &lt;- c(\"NEW JERSEY\", \"NEW YORK\", \"PENNSYLVANIA\")\nd3 &lt;- c(\"ILLINOIS\", \"INDIANA\", \"MICHIGAN\", \"OHIO\", \"WISCONSIN\")\nd4 &lt;- c(\"IOWA\", \"KANSAS\", \"MINNESOTA\", \"MISSOURI\", \"NEBRASKA\", \"NORTH DAKOTA\", \"SOUTH DAKOTA\")\nd5 &lt;- c(\"DELAWARE\", \"FLORIDA\", \"GEORGIA\", \"MARYLAND\", \"NORTH CAROLINA\", \"SOUTH CAROLINA\", \"VIRGINIA\", \"DISTRICT OF COLUMBIA\", \"District of Columbia\", \"WEST VIRGINIA\")\nd6 &lt;- c(\"ALABAMA\", \"KENTUCKY\", \"MISSISSIPPI\", \"TENNESSEE\")\nd7 &lt;- c(\"ARKANSAS\", \"LOUISIANA\", \"OKLAHOMA\", \"TEXAS\")\nd8 &lt;- c(\"ARIZONA\", \"COLORADO\", \"IDAHO\", \"MONTANA\", \"NEVADA\", \"NEW MEXICO\", \"UTAH\", \"WYOMING\")\nd9 &lt;- c(\"ALASKA\", \"CALIFORNIA\", \"HAWAII\", \"OREGON\", \"WASHINGTON\")\n\nregion &lt;- list(d1,d2,d3,d4,d5,d6,d7,d8,d9)\n\nNext we initialize the division vector we want to add, and create a for loop to find it’s values. The strategy in the loop is to look at each row of our noncounty data, then cycle through each element of the region list to find which column contains the state we are looking for. To do so, we utilize a while loop, only iterating to the next list element if our area_name wasn’t in the previous list element (hence the use of the negation operator). Note the use of [[]] as opposed to []– we use the %in% function to check whether our row’s area_name is in a vector.\n\ndivision &lt;- vector()\n\nfor (i in 1:nrow(noncounty)) {\n  j=1\n  while(j&lt;=length(region) && !(noncounty$area_name[i] %in% region[[j]])) {\n    j=j+1\n  }\n  division[i] &lt;- ifelse(j&lt;=length(region), j, \"ERROR\")\n}\n\nnoncounty$division &lt;- division\nnoncounty &lt;- noncounty |&gt; select(area_name, division, everything())\n\n#keep environment clean\nrm(d1,d2,d3,d4,d5,d6,d7,d8,d9,region,division,i,j)\n\nnoncounty\n\n# A tibble: 530 × 7\n   area_name     division STCOU code       survey_type survey_year observed\n   &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n 1 UNITED STATES ERROR    00000 EDU010187D EDU0101            1987 40024299\n 2 UNITED STATES ERROR    00000 EDU010188D EDU0101            1988 39967624\n 3 UNITED STATES ERROR    00000 EDU010189D EDU0101            1989 40317775\n 4 UNITED STATES ERROR    00000 EDU010190D EDU0101            1990 40737600\n 5 UNITED STATES ERROR    00000 EDU010191D EDU0101            1991 41385442\n 6 UNITED STATES ERROR    00000 EDU010192D EDU0101            1992 42088151\n 7 UNITED STATES ERROR    00000 EDU010193D EDU0101            1993 42724710\n 8 UNITED STATES ERROR    00000 EDU010194D EDU0101            1994 43369917\n 9 UNITED STATES ERROR    00000 EDU010195D EDU0101            1995 43993459\n10 UNITED STATES ERROR    00000 EDU010196D EDU0101            1996 44715737\n# ℹ 520 more rows"
  },
  {
    "objectID": "ST558 Project 1 Quarto Doc.html#function-writing",
    "href": "ST558 Project 1 Quarto Doc.html#function-writing",
    "title": "ST558 Project 1",
    "section": "Function Writing",
    "text": "Function Writing\nWe want to create functions that can do all the above with just the input of a file path or url.\nIn the first step to the data processing section above, we looked at selecting, renaming, and reshaping our data. We create a function that performs these steps below, essentially just copying our steps into a user-defined function (udf) called function_for_step_1_2. Note that the input to the function must be a string (i.e. the url must be in quotes).\n\n#create a function to read in csv data and reshaping data from wide to long\nfunction_for_step_1_2 &lt;- function(url, default_var_name=\"observed\") {\n  tmp &lt;- read_csv(url) |&gt;\n    select(Area_name, STCOU, ends_with(\"D\")) |&gt;\n    rename(\"area_name\" = \"Area_name\") |&gt;   \n    pivot_longer(cols = ends_with(\"D\"),\n                 names_to = \"code\",\n                 values_to = default_var_name)\n  return(tmp)\n}\n\nIn the third step to the data processing section above, we looked at parsing strings, specifically breaking up the census code into the survey type and survey year. We again put the process we followed into a single function function_for_step_3 that takes as input the output from function_for_step_1_2. Note that we must have renamed the census codes to code upon reshaping the data in function_for_step_1_2 for this to work.\n\nfunction_for_step_3 &lt;- function(mytibble) {\n  mytibble &lt;- mytibble |&gt;\n  mutate(survey_type = substr(code, 1, 7), \n         survey_year = substr(code, 8, 9)) |&gt;\n  select(area_name, STCOU, code, survey_type, survey_year, everything())\n  \n  mytibble$survey_year &lt;- year(parse_date_time(mytibble$survey_year, \"y\"))\n  \n  return(mytibble)\n}\n\nSkipping a step, in the fifth step to the data processing section above, we looked at parsing our area_name into separate variables for the state and county. We now put this process into a single function function_for_step_5.\n\nfunction_for_step_5 &lt;- function(mytibble) {\n  mytibble &lt;- mytibble |&gt; \n    mutate(state=str_sub(area_name, nchar(mytibble$area_name) - 1,\n                         nchar(mytibble$area_name)),\n           district=str_sub(area_name, 1, nchar(mytibble$area_name)-4)) |&gt;\n    select(area_name, state, district, everything())\n  return(mytibble)\n}\n\nIn the sixth step to the data processing section above, we looked at adding the division of our area_name to the tibble. We now put this process into a single function function_for_step_6.\n\nfunction_for_step_6 &lt;- function(mytibble) {\n  d1 &lt;- c(\"CONNECTICUT\", \"MAINE\", \"MASSACHUSETTS\", \"NEW HAMPSHIRE\", \"RHODE ISLAND\", \"VERMONT\")\n  d2 &lt;- c(\"NEW JERSEY\", \"NEW YORK\", \"PENNSYLVANIA\")\n  d3 &lt;- c(\"ILLINOIS\", \"INDIANA\", \"MICHIGAN\", \"OHIO\", \"WISCONSIN\")\n  d4 &lt;- c(\"IOWA\", \"KANSAS\", \"MINNESOTA\", \"MISSOURI\", \"NEBRASKA\", \"NORTH DAKOTA\", \"SOUTH DAKOTA\")\n  d5 &lt;- c(\"DELAWARE\", \"FLORIDA\", \"GEORGIA\", \"MARYLAND\", \"NORTH CAROLINA\", \"SOUTH CAROLINA\", \"VIRGINIA\", \"DISTRICT OF COLUMBIA\", \"District of Columbia\", \"WEST VIRGINIA\")\n  d6 &lt;- c(\"ALABAMA\", \"KENTUCKY\", \"MISSISSIPPI\", \"TENNESSEE\")\n  d7 &lt;- c(\"ARKANSAS\", \"LOUISIANA\", \"OKLAHOMA\", \"TEXAS\")\n  d8 &lt;- c(\"ARIZONA\", \"COLORADO\", \"IDAHO\", \"MONTANA\", \"NEVADA\", \"NEW MEXICO\", \"UTAH\", \"WYOMING\")\n  d9 &lt;- c(\"ALASKA\", \"CALIFORNIA\", \"HAWAII\", \"OREGON\", \"WASHINGTON\")\n  \n  region &lt;- list(d1,d2,d3,d4,d5,d6,d7,d8,d9)\n  division &lt;- vector()\n  \n  for (i in 1:nrow(mytibble)) {\n    j=1\n    \n    while(j&lt;=length(region) && !(mytibble$area_name[i] %in% region[[j]])) {\n      j=j+1\n    }\n    \n    division[i] &lt;- ifelse(j&lt;=length(region), j, \"ERROR\")\n  }\n  mytibble$division &lt;- division\n  \n  tmp &lt;- mytibble |&gt;\n    select(area_name, division, everything())\n   return(tmp) \n}\n\nWe now return to our skipped fourth step, breaking the data into county and non-county data. Our function just copies our previous procedure in the data prcessing section, and then applies our function_for_step_5 and function_for_step_6 to the split data. We return a list whose first element is our county tibble and whose second element is our noncounty tibble.\n\nfunction_for_step_4_5_6 &lt;- function(mytibble) {\n  a &lt;- str_locate(mytibble$area_name, \",\")[,1]            \n  noncounty &lt;- mytibble[which(is.na(a)),]                 \n  county &lt;- mytibble[which(!is.na(a)),]\n  \n  class(county) &lt;- c(\"county\", class(county))           \n  class(noncounty) &lt;- c(\"state\", class(noncounty))      \n  \n  county &lt;- function_for_step_5(county)\n  noncounty &lt;- function_for_step_6(noncounty)\n  \n  return(list(county,noncounty))\n}\n\nFinally, we create a single wrapper function that brings all of the above functions together.\n\nfunction_wrap &lt;- function(url, default_var_name=\"observed\") {\n  result &lt;- function_for_step_1_2(url, default_var_name) |&gt;\n    function_for_step_3()|&gt;\n    function_for_step_4_5_6()\n  \n  return(result)\n}\n\nWe check that this performs as expected by comparing it’s output to the values we already computed. Using the all.equal function, we see that it does!\n\n  suppressMessages({test=function_wrap(url1)})\n  all.equal(test[[1]], county)\n\n[1] TRUE\n\n  all.equal(test[[2]], noncounty)\n\n[1] TRUE\n\n  rm(test)\n\nWith this function now in hand, we read in both the old data source and a new one accessible at https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv.\n\nurl2 &lt;- \"https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv\"\n\ntibble1 &lt;- function_wrap(url1)\n\nRows: 3198 Columns: 42\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (22): Area_name, STCOU, EDU010187N1, EDU010187N2, EDU010188N1, EDU010188...\ndbl (20): EDU010187F, EDU010187D, EDU010188F, EDU010188D, EDU010189F, EDU010...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntibble2 &lt;- function_wrap(url2)\n\nRows: 3198 Columns: 42\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (22): Area_name, STCOU, EDU010197N1, EDU010197N2, EDU010198N1, EDU010198...\ndbl (20): EDU010197F, EDU010197D, EDU010198F, EDU010198D, EDU010199F, EDU010...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntibble1\n\n[[1]]\n# A tibble: 31,450 × 8\n   area_name   state district STCOU code       survey_type survey_year observed\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n 1 Autauga, AL AL    Autauga  01001 EDU010187D EDU0101            1987     6829\n 2 Autauga, AL AL    Autauga  01001 EDU010188D EDU0101            1988     6900\n 3 Autauga, AL AL    Autauga  01001 EDU010189D EDU0101            1989     6920\n 4 Autauga, AL AL    Autauga  01001 EDU010190D EDU0101            1990     6847\n 5 Autauga, AL AL    Autauga  01001 EDU010191D EDU0101            1991     7008\n 6 Autauga, AL AL    Autauga  01001 EDU010192D EDU0101            1992     7137\n 7 Autauga, AL AL    Autauga  01001 EDU010193D EDU0101            1993     7152\n 8 Autauga, AL AL    Autauga  01001 EDU010194D EDU0101            1994     7381\n 9 Autauga, AL AL    Autauga  01001 EDU010195D EDU0101            1995     7568\n10 Autauga, AL AL    Autauga  01001 EDU010196D EDU0101            1996     7834\n# ℹ 31,440 more rows\n\n[[2]]\n# A tibble: 530 × 7\n   area_name     division STCOU code       survey_type survey_year observed\n   &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n 1 UNITED STATES ERROR    00000 EDU010187D EDU0101            1987 40024299\n 2 UNITED STATES ERROR    00000 EDU010188D EDU0101            1988 39967624\n 3 UNITED STATES ERROR    00000 EDU010189D EDU0101            1989 40317775\n 4 UNITED STATES ERROR    00000 EDU010190D EDU0101            1990 40737600\n 5 UNITED STATES ERROR    00000 EDU010191D EDU0101            1991 41385442\n 6 UNITED STATES ERROR    00000 EDU010192D EDU0101            1992 42088151\n 7 UNITED STATES ERROR    00000 EDU010193D EDU0101            1993 42724710\n 8 UNITED STATES ERROR    00000 EDU010194D EDU0101            1994 43369917\n 9 UNITED STATES ERROR    00000 EDU010195D EDU0101            1995 43993459\n10 UNITED STATES ERROR    00000 EDU010196D EDU0101            1996 44715737\n# ℹ 520 more rows\n\ntibble2\n\n[[1]]\n# A tibble: 31,450 × 8\n   area_name   state district STCOU code       survey_type survey_year observed\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n 1 Autauga, AL AL    Autauga  01001 EDU010197D EDU0101            1997     8099\n 2 Autauga, AL AL    Autauga  01001 EDU010198D EDU0101            1998     8211\n 3 Autauga, AL AL    Autauga  01001 EDU010199D EDU0101            1999     8489\n 4 Autauga, AL AL    Autauga  01001 EDU010200D EDU0102            2000     8912\n 5 Autauga, AL AL    Autauga  01001 EDU010201D EDU0102            2001     8626\n 6 Autauga, AL AL    Autauga  01001 EDU010202D EDU0102            2002     8762\n 7 Autauga, AL AL    Autauga  01001 EDU015203D EDU0152            2003     9105\n 8 Autauga, AL AL    Autauga  01001 EDU015204D EDU0152            2004     9200\n 9 Autauga, AL AL    Autauga  01001 EDU015205D EDU0152            2005     9559\n10 Autauga, AL AL    Autauga  01001 EDU015206D EDU0152            2006     9652\n# ℹ 31,440 more rows\n\n[[2]]\n# A tibble: 530 × 7\n   area_name     division STCOU code       survey_type survey_year observed\n   &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n 1 UNITED STATES ERROR    00000 EDU010197D EDU0101            1997 44534459\n 2 UNITED STATES ERROR    00000 EDU010198D EDU0101            1998 46245814\n 3 UNITED STATES ERROR    00000 EDU010199D EDU0101            1999 46368903\n 4 UNITED STATES ERROR    00000 EDU010200D EDU0102            2000 46818690\n 5 UNITED STATES ERROR    00000 EDU010201D EDU0102            2001 47127066\n 6 UNITED STATES ERROR    00000 EDU010202D EDU0102            2002 47606570\n 7 UNITED STATES ERROR    00000 EDU015203D EDU0152            2003 48506317\n 8 UNITED STATES ERROR    00000 EDU015204D EDU0152            2004 48693287\n 9 UNITED STATES ERROR    00000 EDU015205D EDU0152            2005 48978555\n10 UNITED STATES ERROR    00000 EDU015206D EDU0152            2006 49140702\n# ℹ 520 more rows"
  },
  {
    "objectID": "ST558 Project 1 Quarto Doc.html#call-function-and-combine-data",
    "href": "ST558 Project 1 Quarto Doc.html#call-function-and-combine-data",
    "title": "ST558 Project 1",
    "section": "Call Function And Combine Data",
    "text": "Call Function And Combine Data\nWe then write a function to combine like data with like data (i.e. the county data from the first data source is combined with the county data from the second data source). We use the base function rbind() to do so, though we could also use the dplyr function bind_rows().\n\nfunction_combine &lt;- function(mytib1, mytib2) {\n  county_data &lt;- rbind(mytib1[[1]],mytib2[[1]])\n  non_county_data &lt;- rbind(mytib1[[2]], mytib2[[2]])\n  return(list(county_data, non_county_data))\n}\n\ncombined_data &lt;- function_combine(tibble1,tibble2)\ncombined_data\n\n[[1]]\n# A tibble: 62,900 × 8\n   area_name   state district STCOU code       survey_type survey_year observed\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n 1 Autauga, AL AL    Autauga  01001 EDU010187D EDU0101            1987     6829\n 2 Autauga, AL AL    Autauga  01001 EDU010188D EDU0101            1988     6900\n 3 Autauga, AL AL    Autauga  01001 EDU010189D EDU0101            1989     6920\n 4 Autauga, AL AL    Autauga  01001 EDU010190D EDU0101            1990     6847\n 5 Autauga, AL AL    Autauga  01001 EDU010191D EDU0101            1991     7008\n 6 Autauga, AL AL    Autauga  01001 EDU010192D EDU0101            1992     7137\n 7 Autauga, AL AL    Autauga  01001 EDU010193D EDU0101            1993     7152\n 8 Autauga, AL AL    Autauga  01001 EDU010194D EDU0101            1994     7381\n 9 Autauga, AL AL    Autauga  01001 EDU010195D EDU0101            1995     7568\n10 Autauga, AL AL    Autauga  01001 EDU010196D EDU0101            1996     7834\n# ℹ 62,890 more rows\n\n[[2]]\n# A tibble: 1,060 × 7\n   area_name     division STCOU code       survey_type survey_year observed\n   &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n 1 UNITED STATES ERROR    00000 EDU010187D EDU0101            1987 40024299\n 2 UNITED STATES ERROR    00000 EDU010188D EDU0101            1988 39967624\n 3 UNITED STATES ERROR    00000 EDU010189D EDU0101            1989 40317775\n 4 UNITED STATES ERROR    00000 EDU010190D EDU0101            1990 40737600\n 5 UNITED STATES ERROR    00000 EDU010191D EDU0101            1991 41385442\n 6 UNITED STATES ERROR    00000 EDU010192D EDU0101            1992 42088151\n 7 UNITED STATES ERROR    00000 EDU010193D EDU0101            1993 42724710\n 8 UNITED STATES ERROR    00000 EDU010194D EDU0101            1994 43369917\n 9 UNITED STATES ERROR    00000 EDU010195D EDU0101            1995 43993459\n10 UNITED STATES ERROR    00000 EDU010196D EDU0101            1996 44715737\n# ℹ 1,050 more rows"
  },
  {
    "objectID": "ST558 Project 1 Quarto Doc.html#writing-generic-functions-for-summarizing",
    "href": "ST558 Project 1 Quarto Doc.html#writing-generic-functions-for-summarizing",
    "title": "ST558 Project 1",
    "section": "Writing Generic Functions For Summarizing",
    "text": "Writing Generic Functions For Summarizing\nWe now turn our attention to summarizing our results. We’d like to create functions that utilize the ggplot2() package in the tidyverse to return nice visuals of our data.\n\nMean Enrollemnt By Division\nOur first function will summarize non-county data, returning the mean enrollment value by year for each division that the respective state is in. We only care about divisions, so exclude any values in our data that aren’t part of one by using filter. We want to plot our data for each division by year, so we use group_by() to do so. Finally, we want to find the mean value of each division each year, which we can grab with the summarize() function. We then plot this object using ggplot(), making small adjustments to make the output more visually appealing (such as centering the title with theme(plot.title=element_text(hjust=0.5)) and removing ggplots() ugly default with theme_bw()).\n\nplot_state &lt;- function(mytibble, default_var_name = \"observed\") {\n  mytibble &lt;- mytibble |&gt;\n    filter(division != \"ERROR\") |&gt;\n    group_by(division, survey_year) |&gt;\n    summarize(mean_observed=mean(get(default_var_name)))\n  \n  ggplot(mytibble, aes(x=survey_year, y=mean_observed, color=division)) +\n    geom_line() +\n    labs(x=\"Year\", \n         y=\"Mean Enrollemnt Value\", \n         color=\"Division\", \n         title=\"Mean Enrollment Value by Year and Division\") +\n    theme_bw() +\n    theme(plot.title=element_text(hjust=0.5))\n}\n\nTo make sure the function works as expected, we pass in the output from our combined_data().\n\nplot_state(combined_data[[2]])\n\n`summarise()` has grouped output by 'division'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\n\n\nMean Data By County\nWe want to create a similar function to deal with county data, this time with more flexibility. We’d like to be able to show how only the top (or bottom) counties in a given state change over time. We put in a few default values. For example, if no state is inputted, we also look at North Carolina, if no sort type is provided we always look at the top values, etc. The function first extracts the top/bottom counties in the specified state using normal dplyr functions, then filters the inputted tibble to just those counties, and finally plots how the values change over time in a similar way to our `ggplot2 functions above.\n\nplot_county &lt;- function(mytibble, \n                        default_var_name=\"observed\", \n                        default_state=\"NC\",  \n                        default_sort=\"top\", \n                        default_count=5){\n  \n  if (default_sort == \"top\") {\n    area_name_for_plot=mytibble |&gt;\n      filter(state == default_state) |&gt;\n      group_by(area_name) |&gt;\n      summarize(mean_value = mean(get(default_var_name))) |&gt;\n      arrange(desc(mean_value)) |&gt;\n      slice(1:default_count) |&gt;\n      pull(area_name)\n  } else if (default_sort == \"bottom\") {\n    area_name_for_plot=mytibble |&gt;\n      filter(state == default_state) |&gt;\n      group_by(area_name) |&gt;\n      summarize(mean_value = mean(get(default_var_name))) |&gt;\n      arrange(mean_value) |&gt;\n      slice(1:default_count) |&gt;\n      pull(area_name)\n  } \n  \n  plots_state &lt;- mytibble |&gt;\n    filter(area_name %in% area_name_for_plot)\n  \n  ggplot(plots_state, aes(x = survey_year, y = get(default_var_name), color = area_name)) +\n    geom_line() +\n    labs(x = \"Year\",\n         y = \"Enrollment Value\",\n         color = \"Counties\",\n         title = \"Enrollment Value by Year in Counties Referred\") +\n    theme_bw() +\n    theme(plot.title=element_text(hjust=0.5))\n}\n\nTo make sure it works as expected, we try it on one of our first datasets.\n\nplot_county(combined_data[[1]], \"observed\", \"NC\", \"top\", 5)"
  },
  {
    "objectID": "ST558 Project 1 Quarto Doc.html#put-it-together",
    "href": "ST558 Project 1 Quarto Doc.html#put-it-together",
    "title": "ST558 Project 1",
    "section": "Put It Together",
    "text": "Put It Together\n\nTesting Our Functions\nNow we run data processing function on the two enrollment URLs given previously, specifying a different name “enroll_value” instead of the default value “observed” for the name for the enrollment data column. And then we run the data combining function to put these into one object (with two data frames).\n\n#Read from the first URL\nurl1 &lt;- \"https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv\"\nfirst_urls &lt;- function_wrap(url1, \"enroll_value\")\n\nRows: 3198 Columns: 42\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (22): Area_name, STCOU, EDU010187N1, EDU010187N2, EDU010188N1, EDU010188...\ndbl (20): EDU010187F, EDU010187D, EDU010188F, EDU010188D, EDU010189F, EDU010...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nfirst_urls\n\n[[1]]\n# A tibble: 31,450 × 8\n   area_name   state district STCOU code    survey_type survey_year enroll_value\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;             &lt;dbl&gt;        &lt;dbl&gt;\n 1 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1987         6829\n 2 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1988         6900\n 3 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1989         6920\n 4 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1990         6847\n 5 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1991         7008\n 6 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1992         7137\n 7 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1993         7152\n 8 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1994         7381\n 9 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1995         7568\n10 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1996         7834\n# ℹ 31,440 more rows\n\n[[2]]\n# A tibble: 530 × 7\n   area_name     division STCOU code       survey_type survey_year enroll_value\n   &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;        &lt;dbl&gt;\n 1 UNITED STATES ERROR    00000 EDU010187D EDU0101            1987     40024299\n 2 UNITED STATES ERROR    00000 EDU010188D EDU0101            1988     39967624\n 3 UNITED STATES ERROR    00000 EDU010189D EDU0101            1989     40317775\n 4 UNITED STATES ERROR    00000 EDU010190D EDU0101            1990     40737600\n 5 UNITED STATES ERROR    00000 EDU010191D EDU0101            1991     41385442\n 6 UNITED STATES ERROR    00000 EDU010192D EDU0101            1992     42088151\n 7 UNITED STATES ERROR    00000 EDU010193D EDU0101            1993     42724710\n 8 UNITED STATES ERROR    00000 EDU010194D EDU0101            1994     43369917\n 9 UNITED STATES ERROR    00000 EDU010195D EDU0101            1995     43993459\n10 UNITED STATES ERROR    00000 EDU010196D EDU0101            1996     44715737\n# ℹ 520 more rows\n\n#Read from the second URL\nurl2 &lt;- \"https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv\"\nsecond_urls &lt;- function_wrap(url2, \"enroll_value\")\n\nRows: 3198 Columns: 42\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (22): Area_name, STCOU, EDU010197N1, EDU010197N2, EDU010198N1, EDU010198...\ndbl (20): EDU010197F, EDU010197D, EDU010198F, EDU010198D, EDU010199F, EDU010...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsecond_urls\n\n[[1]]\n# A tibble: 31,450 × 8\n   area_name   state district STCOU code    survey_type survey_year enroll_value\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;             &lt;dbl&gt;        &lt;dbl&gt;\n 1 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1997         8099\n 2 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1998         8211\n 3 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1999         8489\n 4 Autauga, AL AL    Autauga  01001 EDU010… EDU0102            2000         8912\n 5 Autauga, AL AL    Autauga  01001 EDU010… EDU0102            2001         8626\n 6 Autauga, AL AL    Autauga  01001 EDU010… EDU0102            2002         8762\n 7 Autauga, AL AL    Autauga  01001 EDU015… EDU0152            2003         9105\n 8 Autauga, AL AL    Autauga  01001 EDU015… EDU0152            2004         9200\n 9 Autauga, AL AL    Autauga  01001 EDU015… EDU0152            2005         9559\n10 Autauga, AL AL    Autauga  01001 EDU015… EDU0152            2006         9652\n# ℹ 31,440 more rows\n\n[[2]]\n# A tibble: 530 × 7\n   area_name     division STCOU code       survey_type survey_year enroll_value\n   &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;        &lt;dbl&gt;\n 1 UNITED STATES ERROR    00000 EDU010197D EDU0101            1997     44534459\n 2 UNITED STATES ERROR    00000 EDU010198D EDU0101            1998     46245814\n 3 UNITED STATES ERROR    00000 EDU010199D EDU0101            1999     46368903\n 4 UNITED STATES ERROR    00000 EDU010200D EDU0102            2000     46818690\n 5 UNITED STATES ERROR    00000 EDU010201D EDU0102            2001     47127066\n 6 UNITED STATES ERROR    00000 EDU010202D EDU0102            2002     47606570\n 7 UNITED STATES ERROR    00000 EDU015203D EDU0152            2003     48506317\n 8 UNITED STATES ERROR    00000 EDU015204D EDU0152            2004     48693287\n 9 UNITED STATES ERROR    00000 EDU015205D EDU0152            2005     48978555\n10 UNITED STATES ERROR    00000 EDU015206D EDU0152            2006     49140702\n# ℹ 520 more rows\n\ncombined_data &lt;- function_combine(first_urls, second_urls)\ncombined_data\n\n[[1]]\n# A tibble: 62,900 × 8\n   area_name   state district STCOU code    survey_type survey_year enroll_value\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;             &lt;dbl&gt;        &lt;dbl&gt;\n 1 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1987         6829\n 2 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1988         6900\n 3 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1989         6920\n 4 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1990         6847\n 5 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1991         7008\n 6 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1992         7137\n 7 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1993         7152\n 8 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1994         7381\n 9 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1995         7568\n10 Autauga, AL AL    Autauga  01001 EDU010… EDU0101            1996         7834\n# ℹ 62,890 more rows\n\n[[2]]\n# A tibble: 1,060 × 7\n   area_name     division STCOU code       survey_type survey_year enroll_value\n   &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;        &lt;dbl&gt;\n 1 UNITED STATES ERROR    00000 EDU010187D EDU0101            1987     40024299\n 2 UNITED STATES ERROR    00000 EDU010188D EDU0101            1988     39967624\n 3 UNITED STATES ERROR    00000 EDU010189D EDU0101            1989     40317775\n 4 UNITED STATES ERROR    00000 EDU010190D EDU0101            1990     40737600\n 5 UNITED STATES ERROR    00000 EDU010191D EDU0101            1991     41385442\n 6 UNITED STATES ERROR    00000 EDU010192D EDU0101            1992     42088151\n 7 UNITED STATES ERROR    00000 EDU010193D EDU0101            1993     42724710\n 8 UNITED STATES ERROR    00000 EDU010194D EDU0101            1994     43369917\n 9 UNITED STATES ERROR    00000 EDU010195D EDU0101            1995     43993459\n10 UNITED STATES ERROR    00000 EDU010196D EDU0101            1996     44715737\n# ℹ 1,050 more rows\n\n\nWe then use the plot function on the state data.\n\nplot_state(combined_data[[2]], \"enroll_value\")\n\n`summarise()` has grouped output by 'division'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\nThen we look at various iterations of our plot_county() function. First we specify the state to be “NC”, the group being the top, the number looked at being 20.\n\nplot_county(combined_data[[1]], \"enroll_value\", \"NC\", \"top\", 20)\n\n\n\n\n\n\n\n\nNext we specify the state to be South Carolina, the group to be the bottom, and the number being looked at to be 7.\n\nplot_county(combined_data[[1]], \"enroll_value\", \"SC\", \"bottom\", 7)\n\n\n\n\n\n\n\n\nWe can also just use our defaults. Note here we still need to use “enroll_value” since we previously used “enroll_value” as our column name when we read data. If we want to use the default name “observed” for our column name, we need to first read in data with this default name just as the code commented below.\n\nplot_county(combined_data[[1]], default_var_name = \"enroll_value\")\n\n\n\n\n\n\n\n# url1 &lt;- \"https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv\"\n# first_urls &lt;- function_wrap(url1)\n# first_urls\n# \n# url2 &lt;- \"https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv\"\n# second_urls &lt;- function_wrap(url2)\n# second_urls\n# \n# combined_data &lt;- function_combine(first_urls, second_urls)\n# combined_data\n# \n# plot_county(first_urls[[1]])\n\nAnd finally we can specify the state to be Pennsylvania, the group being the top, and the number looked at being 8.\n\nplot_county(combined_data[[1]], \"enroll_value\", \"PA\", \"top\", 8)\n\n\n\n\n\n\n\n\n\n\nAdd New Data\nIn addition to the two urls we already have, we would also like to explore four other data sources. We put these urls into a list, which we plan to loop through in the future.\n\nurl3 &lt;- \"https://www4.stat.ncsu.edu/~online/datasets/PST01a.csv\"\nurl4 &lt;- \"https://www4.stat.ncsu.edu/~online/datasets/PST01b.csv\"\nurl5 &lt;- \"https://www4.stat.ncsu.edu/~online/datasets/PST01c.csv\"\nurl6 &lt;- \"https://www4.stat.ncsu.edu/~online/datasets/PST01d.csv\"\n\nurl_list &lt;- list(url3,url4,url5,url6)\n\nFor each url in our list, we apply our data processing function function_wrap. We create common names for the output of our data sources: data1 for the first url (what we’ve previously called census), data2 for the second, etc.\n\nfor (i in 1:4) {\n  myvar &lt;- paste0(\"data\",i)\n  assign(myvar, function_wrap(url_list[[i]]))\n}\n\nWe then combine the data with our previously created function_combine(). We want to combine the four urls.\n\ncombined_data_1_2 &lt;- function_combine(data1, data2)\ncombined_data_3_4 &lt;- function_combine(data3, data4)\n\ncombined_data_all &lt;- function_combine(combined_data_1_2, combined_data_3_4)\ncombined_data_all\n\n[[1]]\n# A tibble: 125,800 × 8\n   area_name   state district STCOU code       survey_type survey_year observed\n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n 1 Autauga, AL AL    Autauga  01001 PST015171D PST0151            1971    25508\n 2 Autauga, AL AL    Autauga  01001 PST015172D PST0151            1972    27166\n 3 Autauga, AL AL    Autauga  01001 PST015173D PST0151            1973    28463\n 4 Autauga, AL AL    Autauga  01001 PST015174D PST0151            1974    29266\n 5 Autauga, AL AL    Autauga  01001 PST015175D PST0151            1975    29718\n 6 Autauga, AL AL    Autauga  01001 PST015176D PST0151            1976    29896\n 7 Autauga, AL AL    Autauga  01001 PST015177D PST0151            1977    30462\n 8 Autauga, AL AL    Autauga  01001 PST015178D PST0151            1978    30882\n 9 Autauga, AL AL    Autauga  01001 PST015179D PST0151            1979    32055\n10 Autauga, AL AL    Autauga  01001 PST025181D PST0251            1981    31985\n# ℹ 125,790 more rows\n\n[[2]]\n# A tibble: 2,120 × 7\n   area_name     division STCOU code       survey_type survey_year  observed\n   &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;             &lt;dbl&gt;     &lt;dbl&gt;\n 1 UNITED STATES ERROR    00000 PST015171D PST0151            1971 206827028\n 2 UNITED STATES ERROR    00000 PST015172D PST0151            1972 209283904\n 3 UNITED STATES ERROR    00000 PST015173D PST0151            1973 211357490\n 4 UNITED STATES ERROR    00000 PST015174D PST0151            1974 213341552\n 5 UNITED STATES ERROR    00000 PST015175D PST0151            1975 215465246\n 6 UNITED STATES ERROR    00000 PST015176D PST0151            1976 217562728\n 7 UNITED STATES ERROR    00000 PST015177D PST0151            1977 219759860\n 8 UNITED STATES ERROR    00000 PST015178D PST0151            1978 222095080\n 9 UNITED STATES ERROR    00000 PST015179D PST0151            1979 224567234\n10 UNITED STATES ERROR    00000 PST025181D PST0251            1981 229466391\n# ℹ 2,110 more rows\n\n\nWe then use the plot function on the state data frame from above combined four datasets. Note that we used the default variable name when we read in data. Therefore, we don’t specify a different name here and afterwards.\n\nplot_state(combined_data_all[[2]])\n\n`summarise()` has grouped output by 'division'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\nWe can specify our state to be California, the group being the top, and the number looked at being 15 below.\n\nplot_county(combined_data_all[[1]], \"observed\", \"CA\", \"top\", 15)\n\n\n\n\n\n\n\n\nAnoter example is to specify our state to be Texas, the group being the top, and the number being looked at 4 below.\n\nplot_county(combined_data_all[[1]], \"observed\", \"TX\", \"top\", 4)\n\n\n\n\n\n\n\n\nWe can just use our defaults too.\n\nplot_county(combined_data_all[[1]])\n\n\n\n\n\n\n\n\nFinally, we can specify the state to be New York, the group being the top, and the number being looked at to be 10.\n\nplot_county(combined_data_all[[1]], \"observed\", \"NY\", \"top\", 10)"
  }
]