{"title":"ST558 Project 1","markdown":{"yaml":{"title":"ST558 Project 1","author":"Flaherty and Lu","format":"html","editor":"visual"},"headingText":"Data Processing","containsRefs":false,"markdown":"\n\n\nWe are interested in various types of census data, and aim to create functions that return visuals of said data from inputs of either urls or csv files. To start, we look at a single file before generalizing.\n\nThe file was made available at <https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv>. We could either download this locally and save it to our R session, accessing it through the working directory of our projects, or grab the data directly from the url. We opt for the latter. To start our analysis, we installed any packages we might need with `install.packages`, and call them here with `library()`.\n\n```{r, warning = FALSE, message=FALSE}\nlibrary(tidyverse)            \nlibrary(readxl)\n\nurl1 <- \"https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv\"\ncensus <- read_csv(url1)\ncensus\n```\n\n### Initial Data Exploration\nTo get an initial glance at the data, we try normal summary functions. Since the output of these functions is so long, we omit it here. What is clear from the output is that without additional context for what the variables mean, the file contents would be very confusing.\n\n```{r, output=FALSE}\nstr(census)\nsummary(census)\n```\n\nLuckily we are given some of this information. The file contains census data from 2010, with distinct areas in each row, and census surveys in each column. The census surveys follow a code: the first three characters give the survey type (for example **AGE** in the `AGE010180D` code refers to age, while **EDU** in the  `EDU640180D` code refers to education), the next four give the type of value from the survey (for example **6401** in the `EDU640180D` code refers to years of school complete, while **0101** in the `EDU010189D` code refers to public school enrollment), and the next two give the year (for example the **89** in the `EDU010189D` code refers to 1989). There is no data from before 1910. \n\n\n### Data Manipulation And Wrangling\n#### Select, Reshape, And Rename (Step 1 and 2)\n\nAs is, the data is not in a great format for analysis. We want to filter down the data to just the columns we actually care about, and to put it in long format. That is, instead of a distinct area in each row with many different census types in the columns, we want to have just one record for each row, with an additional column added for the census code.\n\nTo choose the columns we want, we use the `select()` function from the `tidyverse`. To keep our naming conventions consistent, we also want to `rename()` certain columns. Additionally, we want to transform our data structure so that the columns holding count data are put in a single column, and the data from those columns put in a new column called `observed`. We can do so with the `pivot_longer()` function. Putting all these steps together with the natural chaining operation `|>`, we can overwrite our object as follows: \n\n```{r}\ncensus <- census |>                   \n  select(Area_name, STCOU, ends_with(\"D\")) |>\n  rename(area_name=Area_name) |>\n  pivot_longer(cols=ends_with(\"D\"),\n               names_to=\"code\",    \n               values_to=\"observed\")\n\ncensus\n```\n\n#### Break Apart Census Code (Step 3)\nIn general, we want the smallest piece of data stored in it's own column. Specific to this file, the census code encodes a lot of information which we'd like to break up so that we can more easily filter it in the future. \n\nOne way to do so is to extract the year from which the survey was conducted on, and store the year and census type in their own columns. Note that direct inspection on a csv file giving information on the variables, namely using `=SORT(UNIQUE(RIGHT(range_of_cells, 4)))`, showed that no data existed prior to 1910-- any two-digit code less than 10 will be from the 2000s.\n\nSince we are in the `tidyverse` already, it makes sense to utilize the `stringr` package to deal with these strings. Within that packages, `str_sub()` extracts parts of a string. Since we know the first 7 characters of our string give the survey type, we can directly extract those to form a new column. Since we know the next two characters of our string give the year, we can append the relevant first two digits to make a year. We have already explained that no data prior to 1910 exists, so know that any data with a year value under 10 will be from the 2000s. \n\n```{r}\ncensus <- census |>\n  mutate(survey_type=str_sub(code, start=1, end=7),\n         survey_year=year(parse_date_time(\n           str_sub(code, start=8, end=9), \"y\"))) |>\n  select(area_name, STCOU, code, survey_type, survey_year, observed)\n\ncensus\n```\n#### Break Into County Vs. Non-County Data  (Step 4)\n\nIn keeping with the above, we'd like to get more granular into our data, specifying the county name when available. To do so, we again rely on the `stringr` package and perform similar operations to the above. \n\nWe first get a sense of the naming patters in our `area_name` column.\n\n```{r}\nunique(census$area_name)[1:10]\n```\n\nNotice that commas exist in areas which have the county specified (like \"Autauga, AL\"), but there are no commas in areas without county-level data (like \"ALABAMA\"). We can split our existing `census` tibble into two different tibbles, one with county-level data and one without, by searching for the rows in the tibble which have a comma. The `str_locate()` function in the `stringr` package does the trick, taking in our vector of `area_name`'s, searching for the comma, and returning a matrix giving the starting and ending character of where the comma exists. Since a comma is only one character, we only need one of these columns, and so return just the first column from our matrix. \n\n```{r}\na <- str_locate(census$area_name, \",\")[,1]            #dummy object, no commas in non-county#\nnoncounty <- census[which(is.na(a)),]                 #keep non-county data together#\ncounty <- census[which(!is.na(a)),]                   #keep county data together#\nrm(a)                                                 #no need to keep#\n\nnoncounty\ncounty\n```\n\nWe can double check that this split worked as expected with `unique` from base R.\n\n```{r}\nunique(noncounty$area_name)                        \nunique(county$area_name)[1:50]\n```\n\nAfter verifying that the split worked as intended, we add a class to each tibble, overwriting the previous one.\n\n```{r}\nclass(county) <- c(\"county\", class(county))           \nclass(noncounty) <- c(\"state\", class(noncounty))\n\nclass(county)\nclass(noncounty)\n```\n\n#### Classifying States And Counties (Step 5)\nWith the distinct tables now in hand, we want to break up the `area_name` to both the county and state in the case of the `county` data, and to include the division in the case of the `noncounty` data. \n\nIn the `county` data, we are just extracting the last two characters of the string for the state abbreviation, and all parts of the string less the last four for the county (two for the state abbreviation, one for the space, one for the comma). We can do this succinctly with the same `str_sub()` function, utilizing the `nchar()` function in the process (which logically returns the number of characters a string has).\n\n```{r}\ncounty <- county |>\n  mutate(state=str_sub(area_name, nchar(county$area_name) - 1, nchar(county$area_name)),\n         district=str_sub(area_name, 1, nchar(county$area_name)-4)) |>\n  select(area_name, state, district, everything())\n\ncounty\n```\n\n#### Classifying States And Divisions (Step 6)\nIn the `noncounty` data, we are adding a variable corresponding to the state's classification of divisions found at [https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States?useskin=vector](https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States?useskin=vector). We store these classifications in a list called `region`. Note that the syntax of the strings in our list was choosen to follow the syntax of the names which exist in our `noncounty$area_name`.\n\n```{r}\nd1 <- c(\"CONNECTICUT\", \"MAINE\", \"MASSACHUSETTS\", \"NEW HAMPSHIRE\", \"RHODE ISLAND\", \"VERMONT\")\nd2 <- c(\"NEW JERSEY\", \"NEW YORK\", \"PENNSYLVANIA\")\nd3 <- c(\"ILLINOIS\", \"INDIANA\", \"MICHIGAN\", \"OHIO\", \"WISCONSIN\")\nd4 <- c(\"IOWA\", \"KANSAS\", \"MINNESOTA\", \"MISSOURI\", \"NEBRASKA\", \"NORTH DAKOTA\", \"SOUTH DAKOTA\")\nd5 <- c(\"DELAWARE\", \"FLORIDA\", \"GEORGIA\", \"MARYLAND\", \"NORTH CAROLINA\", \"SOUTH CAROLINA\", \"VIRGINIA\", \"DISTRICT OF COLUMBIA\", \"District of Columbia\", \"WEST VIRGINIA\")\nd6 <- c(\"ALABAMA\", \"KENTUCKY\", \"MISSISSIPPI\", \"TENNESSEE\")\nd7 <- c(\"ARKANSAS\", \"LOUISIANA\", \"OKLAHOMA\", \"TEXAS\")\nd8 <- c(\"ARIZONA\", \"COLORADO\", \"IDAHO\", \"MONTANA\", \"NEVADA\", \"NEW MEXICO\", \"UTAH\", \"WYOMING\")\nd9 <- c(\"ALASKA\", \"CALIFORNIA\", \"HAWAII\", \"OREGON\", \"WASHINGTON\")\n\nregion <- list(d1,d2,d3,d4,d5,d6,d7,d8,d9)\n```\n\nNext we initialize the `division` vector we want to add, and create a `for()` loop to find it's values. The strategy in the loop is to look at each row of our `noncounty` data, then cycle through each element of the `region` list to find which column contains the state we are looking for. To do so, we utilize a `while` loop, only iterating to the next list element if our `area_name` wasn't in the previous list element (hence the use of the negation operator). Note the use of `[[]]` as opposed to `[]`-- we use the `%in%` function to check whether our row's `area_name` is in a *vector*. \n\n\n```{r}\ndivision <- vector()\n\nfor (i in 1:nrow(noncounty)) {\n  j=1\n  while(j<=length(region) && !(noncounty$area_name[i] %in% region[[j]])) {\n    j=j+1\n  }\n  division[i]=ifelse(j<=length(region), j, \"ERROR\")\n}\n\nnoncounty$division=division\nnoncounty=noncounty |> select(area_name, division, everything())\n\nrm(d1,d2,d3,d4,d5,d6,d7,d8,d9,region,division,i,j)      #keep environment clean#\n\nnoncounty\n```\n\n\n## Function Writing\n\nWe want to create functions that can do all the above with just the input of a file path or url. \n\nIn the first step to the data processing section above, we looked at selecting, renaming, and reshaping our data. We create a function that performs these steps below, essentially just copying our steps into a user-defined function (udf) called  `function_for_step_1_2`. Note that the input to the function must be a string (i.e. the url must be in quotes).\n\n\n```{r}\nfunction_for_step_1_2 <- function(url, default_var_name=\"observed\") {\n  tmp=read_csv(url) |>\n    select(Area_name, STCOU, ends_with(\"D\")) |>\n    rename(area_name = Area_name) |>   \n    pivot_longer(cols = ends_with(\"D\"),\n                 names_to = \"code\",\n                 values_to = default_var_name)\n  return(tmp)\n}\n```\n\nIn the third step to the data processing section above, we looked at parsing strings, specifically breaking up the census code into the survey type and survey year. We again put the process we followed into a single function `function_for_step_3` that takes as input the output from `function_for_step_1_2`. Note that we must have renamed the census codes to `code` upon reshaping the data in `function_for_step_1_2` for this to work. \n\n\n```{r}\nfunction_for_step_3 <- function(mytibble) {\n  tmp <- mytibble |>\n  mutate(survey_type=str_sub(code, start=1, end=7),\n         survey_year=year(parse_date_time(\n           str_sub(code, start=8, end=9), \"y\"))) |>\n  select(area_name, STCOU, code, survey_type, survey_year, observed)\n  \n  return(tmp)\n}\n```\n\nSkipping a step, in the fifth step to the data processing section above, we looked at parsing our `area_name` into separate variables for the `state` and `county`. We now put this process into a single function `function_for_step_5`. \n\n```{r}\nfunction_for_step_5 <- function(mytibble) {\n  tmp=mytibble |> \n    mutate(state=str_sub(area_name, nchar(mytibble$area_name) - 1, nchar(mytibble$area_name)),\n           district=str_sub(area_name, 1, nchar(mytibble$area_name)-4)) |>\n    select(area_name, state, district, everything())\n  return(tmp)\n}\n```\n\nIn the sixth step to the data processing section above, we looked at adding the division of our `area_name` to the tibble. We now put this process into a single function `function_for_step_6`. \n\n```{r}\nfunction_for_step_6 <- function(mytibble) {\n  d1=c(\"CONNECTICUT\", \"MAINE\", \"MASSACHUSETTS\", \"NEW HAMPSHIRE\", \"RHODE ISLAND\", \"VERMONT\")\n  d2=c(\"NEW JERSEY\", \"NEW YORK\", \"PENNSYLVANIA\")\n  d3=c(\"ILLINOIS\", \"INDIANA\", \"MICHIGAN\", \"OHIO\", \"WISCONSIN\")\n  d4=c(\"IOWA\", \"KANSAS\", \"MINNESOTA\", \"MISSOURI\", \"NEBRASKA\", \"NORTH DAKOTA\", \"SOUTH DAKOTA\")\n  d5=c(\"DELAWARE\", \"FLORIDA\", \"GEORGIA\", \"MARYLAND\", \"NORTH CAROLINA\", \"SOUTH CAROLINA\", \"VIRGINIA\", \"DISTRICT OF COLUMBIA\", \"District of Columbia\", \"WEST VIRGINIA\")\n  d6=c(\"ALABAMA\", \"KENTUCKY\", \"MISSISSIPPI\", \"TENNESSEE\")\n  d7=c(\"ARKANSAS\", \"LOUISIANA\", \"OKLAHOMA\", \"TEXAS\")\n  d8=c(\"ARIZONA\", \"COLORADO\", \"IDAHO\", \"MONTANA\", \"NEVADA\", \"NEW MEXICO\", \"UTAH\", \"WYOMING\")\n  d9=c(\"ALASKA\", \"CALIFORNIA\", \"HAWAII\", \"OREGON\", \"WASHINGTON\")\n  \n  region=list(d1,d2,d3,d4,d5,d6,d7,d8,d9)\n  division=vector()\n  \n  for (i in 1:nrow(mytibble)) {\n    j=1\n    \n    while(j<=length(region) && !(mytibble$area_name[i] %in% region[[j]])) {\n      j=j+1\n    }\n    \n    division[i]=ifelse(j<=length(region), j, \"ERROR\")\n  }\n  mytibble$division=division\n  \n  tmp=mytibble |>\n    select(area_name, division, everything())\n   return(tmp) \n}\n```\n\nWe now return to our skipped fourth step, breaking the data into county and non-county data. Our function just copies our previous procedure in the data prcessing section, and then applies our `function_for_step_5` and `function_for_step_6` to the split data. We return a list whose first element is our `county` tibble and whose second element is our `noncounty` tibble.\n\n```{r}\nfunction_for_step_4_5_6 <- function(mytibble) {\n  a=str_locate(mytibble$area_name, \",\")[,1]            \n  noncounty=mytibble[which(is.na(a)),]                 \n  county=mytibble[which(!is.na(a)),]\n  \n  class(county)=c(\"county\", class(county))           \n  class(noncounty)=c(\"state\", class(noncounty))      \n  \n  county=function_for_step_5(county)\n  noncounty=function_for_step_6(noncounty)\n  \n  return(list(county,noncounty))\n}\n```\n\nFinally, we create a single wrapper function that brings all of the above functions together.\n\n```{r}\nfunction_wrap <- function(url, default_var_name=\"observed\") {\n  result=function_for_step_1_2(url, default_var_name) |>\n    function_for_step_3()|>\n    function_for_step_4_5_6()\n  \n  return(result)\n}\n```\n\nWe check that this performs as expected by comparing it's output to the values we already computed. Using the `all.equal` function, we see that it does!\n\n```{r, output=FALSE}\n  test=function_wrap(url1)\n```\n\n```{r}\n  all.equal(test[[1]], county)\n  all.equal(test[[2]], noncounty)\n  rm(test)\n```\n\nWith this function now in hand, we read in both the old data source and a new one accessible at [https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv](https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv).\n\n```{r, output=FALSE}\nurl2 <- \"https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv\"\n\ntibble1 <- function_wrap(url1)\ntibble2 <- function_wrap(url2)\n```\n\n```{r}\ntibble1\ntibble2\n```\n\n## Call Function And Combine Data\nWe then write a function to combine like data with like data (i.e. the county data from the first data source is combined with the county data from the second data source). We use the base function `rbind()` to do so, though we could also use the `dplyr` function `bind_rows()`.\n\n```{r}\nfunction_combine <- function(mytib1, mytib2) {\n  county_data=rbind(mytib1[[1]],mytib2[[1]])\n  non_county_data=rbind(mytib1[[2]], mytib2[[2]])\n  return(list(county_data, non_county_data))\n}\n\ncombined_data <- function_combine(tibble1,tibble2)\ncombined_data\n```\n\n\n## Writing Generic Functions For Summarizing\nWe now turn our attention to summarizing our results. We'd like to create functions that utilize the `ggplot2` package in the `tidyverse` to return nice visuals of our data.\n\n### Mean Enrollemnt By Division\nOur first function will summarize non-county data, returning the mean enrollment value by year for each division that the respective state is in. We only care about divisions, so exclude any values in our data that  aren't part of one by using `filter`. We want to plot our data for each division by year, so we use `group_by()` to do so. Finally, we want to find the mean value of each division each year, which we can grab with the `summarize()` function. We then plot this object using `ggplot()`, making small adjustments to make the output more visually appealing (such as centering the title with `theme(plot.title=element_text(hjust=0.5))` and removing `ggplots()` ugly default with ` theme_bw()`). \n\n```{r}\nplot_state <- function(mytibble, default_var_name=\"observed\") {\n  tmp=mytibble |>\n    filter(division != \"ERROR\") |>\n    group_by(division, survey_year) |>\n    summarize(mean_observed=mean(get(default_var_name)))\n  \n  ggplot(tmp, aes(x=survey_year, y=mean_observed, color=division)) +\n    geom_line() +\n    labs(x=\"Year\", \n         y=\"Mean Enrollemnt Value\", \n         color=\"Division\", \n         title=\"Mean Enrollment Value by Year and Division\") +\n    theme_bw() +\n    theme(plot.title=element_text(hjust=0.5))\n}\n```\n\nTo make sure the function works as expected, we pass in the output from our `combined_data()`.\n\n```{r}\nplot_state(combined_data[[2]])\n```\n### Mean Data By County\n\nWe want to create a similar function to deal with county data, this time with more flexibility. We'd like to be able to show how only the top (or bottom) counties in a given state change over time. We put in a few default values. For example, if no state is inputted, we also look at North Carolina, if no sort type is provided we always look at the top values, etc. The function first extracts the top/bottom counties in the specified state using normal `dplyr` functions, then filters the inputted tibble to just those counties, and finally plots how the values change over time in a similar way to our ``ggplot2` functions above.\n\n\n```{r}\nplot_county <- function(mytibble, \n                        default_var_name=\"observed\", \n                        default_state=\"NC\",  \n                        default_sort=\"top\", \n                        default_count=5){\n  \n  if (default_sort == \"top\") {\n    area_name_for_plot=mytibble |>\n      filter(state == default_state) |>\n      group_by(area_name) |>\n      summarize(mean_value = mean(get(default_var_name))) |>\n      arrange(desc(mean_value)) |>\n      slice(1:default_count) |>\n      pull(area_name)\n  } else if (default_sort == \"bottom\") {\n    area_name_for_plot=mytibble |>\n      filter(state == default_state) |>\n      group_by(area_name) |>\n      summarize(mean_value = mean(get(default_var_name))) |>\n      arrange(mean_value) |>\n      slice(1:default_count) |>\n      pull(area_name)\n  } \n  \n  plot_state=mytibble |>\n    filter(area_name %in% area_name_for_plot)\n  \n  ggplot(plot_state, aes(x = survey_year, y = get(default_var_name), color = area_name)) +\n    geom_line() +\n    labs(x = \"Year\",\n         y = \"Enrollment Value\",\n         color = \"Counties\",\n         title = \"Enrollment Value by Year in Counties Referred\") +\n    theme_bw() +\n    theme(plot.title=element_text(hjust=0.5))\n}\n```\n\nTo make sure it works as expected, we try it on one of our first datasets.\n\n\n```{r}\nplot_county(county)\n```\n\n\n## Put It Together\n\n### Add New Data\nIn addition to the two urls we already have, we would also like to explore four other data sources. We put these urls into a list, which we plan to loop through in the future.\n\n```{r}\nurl3=\"https://www4.stat.ncsu.edu/~online/datasets/PST01a.csv\"\nurl4=\"https://www4.stat.ncsu.edu/~online/datasets/PST01b.csv\"\nurl5=\"https://www4.stat.ncsu.edu/~online/datasets/PST01c.csv\"\nurl6=\"https://www4.stat.ncsu.edu/~online/datasets/PST01d.csv\"\n\nurl_list <- list(url1, url2,url3,url4,url5,url6)\nrm(url1,url2,url3,url4,url5,url6)\n```\n\nFor each url in our list, we apply our data processing function `function_wrap`. We create common names for the output of our data sources: `data1` for the first url (what we've previously called `census`), `data2` for the second, etc.\n\n```{r, output=FALSE}\nfor (i in 1:6) {\n  myvar=paste0(\"data\",i)\n  assign(myvar, function_wrap(url_list[[i]]))\n}\n\nrm(i, myvar)\n```\n\nWe then combine the data with our previously created `function_combine()`. We want to combine the first two urls and the last four urls.\n\n```{r}\nfirst_urls <- function_combine(data1,data2)\nsecond_urls <- function_combine(data3,\n  function_combine(data4,\n    function_combine(data5, data6)))\n\nrm(data1,data2,data3,data4,data5,data6)\n\nfirst_urls\nsecond_urls\n```\n\n### Testing Our Functions\n#### First Group Of URLs\n\nNow we test our functions! First on our first urls. We look at the divsion data with our `plot_state()` function.\n\n```{r}\nplot_state(first_urls[[2]])\n```\n\nThen we look at various iterations of our `plot_county()` funciton. First we specify the state to be “NC”, the group being the top, the number looked at being 20.\n\n```{r}\nplot_county(first_urls[[1]], \"observed\", \"NC\", \"top\", 20)\n```\nNext we specify the state to be South Carolina, the group to be the bottom, and the number being looked at to be 7.\n\n```{r}\nplot_county(first_urls[[1]], \"observed\", \"SC\", \"bottom\", 7)\n```\n\nWe can also just use our defaults.\n\n```{r}\nplot_county(first_urls[[1]])\n```\nAnd finally we can specify the state to be Pennsylvania, the group being the top, and the number looked at being 8.\n\n```{r}\nplot_county(first_urls[[1]], \"observed\", \"PA\", \"top\", 8)\n```\n\n#### Second Group Of URLs\n\nWe now move our attention to the second group of urls. We can examine the divisions with our `plot_state()` function.\n\n```{r}\nplot_state(second_urls[[2]])\n```\n\nWe can specify our state to be California, the group being the top, and the number looked at being 15 below.\n\n```{r}\nplot_county(second_urls[[1]], \"observed\", \"CA\", \"top\", 15)\n```\n\nAnoter example is to specify our state to be Texas, the group being the top, and the number being looked at 4 below. \n\n```{r}\nplot_county(second_urls[[1]], \"observed\", \"TX\", \"top\", 4)\n```\n\nWe can just use our defaults too.\n\n```{r}\nplot_county(second_urls[[1]])\n```\n\nFinally, we can specify the state to be New York, the group being the top, and the number being looked at to be 10.\n\n```{r}\nplot_county(second_urls[[1]], \"observed\", \"NY\", \"top\", 10)\n```\n","srcMarkdownNoYaml":"\n\n## Data Processing\n\nWe are interested in various types of census data, and aim to create functions that return visuals of said data from inputs of either urls or csv files. To start, we look at a single file before generalizing.\n\nThe file was made available at <https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv>. We could either download this locally and save it to our R session, accessing it through the working directory of our projects, or grab the data directly from the url. We opt for the latter. To start our analysis, we installed any packages we might need with `install.packages`, and call them here with `library()`.\n\n```{r, warning = FALSE, message=FALSE}\nlibrary(tidyverse)            \nlibrary(readxl)\n\nurl1 <- \"https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv\"\ncensus <- read_csv(url1)\ncensus\n```\n\n### Initial Data Exploration\nTo get an initial glance at the data, we try normal summary functions. Since the output of these functions is so long, we omit it here. What is clear from the output is that without additional context for what the variables mean, the file contents would be very confusing.\n\n```{r, output=FALSE}\nstr(census)\nsummary(census)\n```\n\nLuckily we are given some of this information. The file contains census data from 2010, with distinct areas in each row, and census surveys in each column. The census surveys follow a code: the first three characters give the survey type (for example **AGE** in the `AGE010180D` code refers to age, while **EDU** in the  `EDU640180D` code refers to education), the next four give the type of value from the survey (for example **6401** in the `EDU640180D` code refers to years of school complete, while **0101** in the `EDU010189D` code refers to public school enrollment), and the next two give the year (for example the **89** in the `EDU010189D` code refers to 1989). There is no data from before 1910. \n\n\n### Data Manipulation And Wrangling\n#### Select, Reshape, And Rename (Step 1 and 2)\n\nAs is, the data is not in a great format for analysis. We want to filter down the data to just the columns we actually care about, and to put it in long format. That is, instead of a distinct area in each row with many different census types in the columns, we want to have just one record for each row, with an additional column added for the census code.\n\nTo choose the columns we want, we use the `select()` function from the `tidyverse`. To keep our naming conventions consistent, we also want to `rename()` certain columns. Additionally, we want to transform our data structure so that the columns holding count data are put in a single column, and the data from those columns put in a new column called `observed`. We can do so with the `pivot_longer()` function. Putting all these steps together with the natural chaining operation `|>`, we can overwrite our object as follows: \n\n```{r}\ncensus <- census |>                   \n  select(Area_name, STCOU, ends_with(\"D\")) |>\n  rename(area_name=Area_name) |>\n  pivot_longer(cols=ends_with(\"D\"),\n               names_to=\"code\",    \n               values_to=\"observed\")\n\ncensus\n```\n\n#### Break Apart Census Code (Step 3)\nIn general, we want the smallest piece of data stored in it's own column. Specific to this file, the census code encodes a lot of information which we'd like to break up so that we can more easily filter it in the future. \n\nOne way to do so is to extract the year from which the survey was conducted on, and store the year and census type in their own columns. Note that direct inspection on a csv file giving information on the variables, namely using `=SORT(UNIQUE(RIGHT(range_of_cells, 4)))`, showed that no data existed prior to 1910-- any two-digit code less than 10 will be from the 2000s.\n\nSince we are in the `tidyverse` already, it makes sense to utilize the `stringr` package to deal with these strings. Within that packages, `str_sub()` extracts parts of a string. Since we know the first 7 characters of our string give the survey type, we can directly extract those to form a new column. Since we know the next two characters of our string give the year, we can append the relevant first two digits to make a year. We have already explained that no data prior to 1910 exists, so know that any data with a year value under 10 will be from the 2000s. \n\n```{r}\ncensus <- census |>\n  mutate(survey_type=str_sub(code, start=1, end=7),\n         survey_year=year(parse_date_time(\n           str_sub(code, start=8, end=9), \"y\"))) |>\n  select(area_name, STCOU, code, survey_type, survey_year, observed)\n\ncensus\n```\n#### Break Into County Vs. Non-County Data  (Step 4)\n\nIn keeping with the above, we'd like to get more granular into our data, specifying the county name when available. To do so, we again rely on the `stringr` package and perform similar operations to the above. \n\nWe first get a sense of the naming patters in our `area_name` column.\n\n```{r}\nunique(census$area_name)[1:10]\n```\n\nNotice that commas exist in areas which have the county specified (like \"Autauga, AL\"), but there are no commas in areas without county-level data (like \"ALABAMA\"). We can split our existing `census` tibble into two different tibbles, one with county-level data and one without, by searching for the rows in the tibble which have a comma. The `str_locate()` function in the `stringr` package does the trick, taking in our vector of `area_name`'s, searching for the comma, and returning a matrix giving the starting and ending character of where the comma exists. Since a comma is only one character, we only need one of these columns, and so return just the first column from our matrix. \n\n```{r}\na <- str_locate(census$area_name, \",\")[,1]            #dummy object, no commas in non-county#\nnoncounty <- census[which(is.na(a)),]                 #keep non-county data together#\ncounty <- census[which(!is.na(a)),]                   #keep county data together#\nrm(a)                                                 #no need to keep#\n\nnoncounty\ncounty\n```\n\nWe can double check that this split worked as expected with `unique` from base R.\n\n```{r}\nunique(noncounty$area_name)                        \nunique(county$area_name)[1:50]\n```\n\nAfter verifying that the split worked as intended, we add a class to each tibble, overwriting the previous one.\n\n```{r}\nclass(county) <- c(\"county\", class(county))           \nclass(noncounty) <- c(\"state\", class(noncounty))\n\nclass(county)\nclass(noncounty)\n```\n\n#### Classifying States And Counties (Step 5)\nWith the distinct tables now in hand, we want to break up the `area_name` to both the county and state in the case of the `county` data, and to include the division in the case of the `noncounty` data. \n\nIn the `county` data, we are just extracting the last two characters of the string for the state abbreviation, and all parts of the string less the last four for the county (two for the state abbreviation, one for the space, one for the comma). We can do this succinctly with the same `str_sub()` function, utilizing the `nchar()` function in the process (which logically returns the number of characters a string has).\n\n```{r}\ncounty <- county |>\n  mutate(state=str_sub(area_name, nchar(county$area_name) - 1, nchar(county$area_name)),\n         district=str_sub(area_name, 1, nchar(county$area_name)-4)) |>\n  select(area_name, state, district, everything())\n\ncounty\n```\n\n#### Classifying States And Divisions (Step 6)\nIn the `noncounty` data, we are adding a variable corresponding to the state's classification of divisions found at [https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States?useskin=vector](https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States?useskin=vector). We store these classifications in a list called `region`. Note that the syntax of the strings in our list was choosen to follow the syntax of the names which exist in our `noncounty$area_name`.\n\n```{r}\nd1 <- c(\"CONNECTICUT\", \"MAINE\", \"MASSACHUSETTS\", \"NEW HAMPSHIRE\", \"RHODE ISLAND\", \"VERMONT\")\nd2 <- c(\"NEW JERSEY\", \"NEW YORK\", \"PENNSYLVANIA\")\nd3 <- c(\"ILLINOIS\", \"INDIANA\", \"MICHIGAN\", \"OHIO\", \"WISCONSIN\")\nd4 <- c(\"IOWA\", \"KANSAS\", \"MINNESOTA\", \"MISSOURI\", \"NEBRASKA\", \"NORTH DAKOTA\", \"SOUTH DAKOTA\")\nd5 <- c(\"DELAWARE\", \"FLORIDA\", \"GEORGIA\", \"MARYLAND\", \"NORTH CAROLINA\", \"SOUTH CAROLINA\", \"VIRGINIA\", \"DISTRICT OF COLUMBIA\", \"District of Columbia\", \"WEST VIRGINIA\")\nd6 <- c(\"ALABAMA\", \"KENTUCKY\", \"MISSISSIPPI\", \"TENNESSEE\")\nd7 <- c(\"ARKANSAS\", \"LOUISIANA\", \"OKLAHOMA\", \"TEXAS\")\nd8 <- c(\"ARIZONA\", \"COLORADO\", \"IDAHO\", \"MONTANA\", \"NEVADA\", \"NEW MEXICO\", \"UTAH\", \"WYOMING\")\nd9 <- c(\"ALASKA\", \"CALIFORNIA\", \"HAWAII\", \"OREGON\", \"WASHINGTON\")\n\nregion <- list(d1,d2,d3,d4,d5,d6,d7,d8,d9)\n```\n\nNext we initialize the `division` vector we want to add, and create a `for()` loop to find it's values. The strategy in the loop is to look at each row of our `noncounty` data, then cycle through each element of the `region` list to find which column contains the state we are looking for. To do so, we utilize a `while` loop, only iterating to the next list element if our `area_name` wasn't in the previous list element (hence the use of the negation operator). Note the use of `[[]]` as opposed to `[]`-- we use the `%in%` function to check whether our row's `area_name` is in a *vector*. \n\n\n```{r}\ndivision <- vector()\n\nfor (i in 1:nrow(noncounty)) {\n  j=1\n  while(j<=length(region) && !(noncounty$area_name[i] %in% region[[j]])) {\n    j=j+1\n  }\n  division[i]=ifelse(j<=length(region), j, \"ERROR\")\n}\n\nnoncounty$division=division\nnoncounty=noncounty |> select(area_name, division, everything())\n\nrm(d1,d2,d3,d4,d5,d6,d7,d8,d9,region,division,i,j)      #keep environment clean#\n\nnoncounty\n```\n\n\n## Function Writing\n\nWe want to create functions that can do all the above with just the input of a file path or url. \n\nIn the first step to the data processing section above, we looked at selecting, renaming, and reshaping our data. We create a function that performs these steps below, essentially just copying our steps into a user-defined function (udf) called  `function_for_step_1_2`. Note that the input to the function must be a string (i.e. the url must be in quotes).\n\n\n```{r}\nfunction_for_step_1_2 <- function(url, default_var_name=\"observed\") {\n  tmp=read_csv(url) |>\n    select(Area_name, STCOU, ends_with(\"D\")) |>\n    rename(area_name = Area_name) |>   \n    pivot_longer(cols = ends_with(\"D\"),\n                 names_to = \"code\",\n                 values_to = default_var_name)\n  return(tmp)\n}\n```\n\nIn the third step to the data processing section above, we looked at parsing strings, specifically breaking up the census code into the survey type and survey year. We again put the process we followed into a single function `function_for_step_3` that takes as input the output from `function_for_step_1_2`. Note that we must have renamed the census codes to `code` upon reshaping the data in `function_for_step_1_2` for this to work. \n\n\n```{r}\nfunction_for_step_3 <- function(mytibble) {\n  tmp <- mytibble |>\n  mutate(survey_type=str_sub(code, start=1, end=7),\n         survey_year=year(parse_date_time(\n           str_sub(code, start=8, end=9), \"y\"))) |>\n  select(area_name, STCOU, code, survey_type, survey_year, observed)\n  \n  return(tmp)\n}\n```\n\nSkipping a step, in the fifth step to the data processing section above, we looked at parsing our `area_name` into separate variables for the `state` and `county`. We now put this process into a single function `function_for_step_5`. \n\n```{r}\nfunction_for_step_5 <- function(mytibble) {\n  tmp=mytibble |> \n    mutate(state=str_sub(area_name, nchar(mytibble$area_name) - 1, nchar(mytibble$area_name)),\n           district=str_sub(area_name, 1, nchar(mytibble$area_name)-4)) |>\n    select(area_name, state, district, everything())\n  return(tmp)\n}\n```\n\nIn the sixth step to the data processing section above, we looked at adding the division of our `area_name` to the tibble. We now put this process into a single function `function_for_step_6`. \n\n```{r}\nfunction_for_step_6 <- function(mytibble) {\n  d1=c(\"CONNECTICUT\", \"MAINE\", \"MASSACHUSETTS\", \"NEW HAMPSHIRE\", \"RHODE ISLAND\", \"VERMONT\")\n  d2=c(\"NEW JERSEY\", \"NEW YORK\", \"PENNSYLVANIA\")\n  d3=c(\"ILLINOIS\", \"INDIANA\", \"MICHIGAN\", \"OHIO\", \"WISCONSIN\")\n  d4=c(\"IOWA\", \"KANSAS\", \"MINNESOTA\", \"MISSOURI\", \"NEBRASKA\", \"NORTH DAKOTA\", \"SOUTH DAKOTA\")\n  d5=c(\"DELAWARE\", \"FLORIDA\", \"GEORGIA\", \"MARYLAND\", \"NORTH CAROLINA\", \"SOUTH CAROLINA\", \"VIRGINIA\", \"DISTRICT OF COLUMBIA\", \"District of Columbia\", \"WEST VIRGINIA\")\n  d6=c(\"ALABAMA\", \"KENTUCKY\", \"MISSISSIPPI\", \"TENNESSEE\")\n  d7=c(\"ARKANSAS\", \"LOUISIANA\", \"OKLAHOMA\", \"TEXAS\")\n  d8=c(\"ARIZONA\", \"COLORADO\", \"IDAHO\", \"MONTANA\", \"NEVADA\", \"NEW MEXICO\", \"UTAH\", \"WYOMING\")\n  d9=c(\"ALASKA\", \"CALIFORNIA\", \"HAWAII\", \"OREGON\", \"WASHINGTON\")\n  \n  region=list(d1,d2,d3,d4,d5,d6,d7,d8,d9)\n  division=vector()\n  \n  for (i in 1:nrow(mytibble)) {\n    j=1\n    \n    while(j<=length(region) && !(mytibble$area_name[i] %in% region[[j]])) {\n      j=j+1\n    }\n    \n    division[i]=ifelse(j<=length(region), j, \"ERROR\")\n  }\n  mytibble$division=division\n  \n  tmp=mytibble |>\n    select(area_name, division, everything())\n   return(tmp) \n}\n```\n\nWe now return to our skipped fourth step, breaking the data into county and non-county data. Our function just copies our previous procedure in the data prcessing section, and then applies our `function_for_step_5` and `function_for_step_6` to the split data. We return a list whose first element is our `county` tibble and whose second element is our `noncounty` tibble.\n\n```{r}\nfunction_for_step_4_5_6 <- function(mytibble) {\n  a=str_locate(mytibble$area_name, \",\")[,1]            \n  noncounty=mytibble[which(is.na(a)),]                 \n  county=mytibble[which(!is.na(a)),]\n  \n  class(county)=c(\"county\", class(county))           \n  class(noncounty)=c(\"state\", class(noncounty))      \n  \n  county=function_for_step_5(county)\n  noncounty=function_for_step_6(noncounty)\n  \n  return(list(county,noncounty))\n}\n```\n\nFinally, we create a single wrapper function that brings all of the above functions together.\n\n```{r}\nfunction_wrap <- function(url, default_var_name=\"observed\") {\n  result=function_for_step_1_2(url, default_var_name) |>\n    function_for_step_3()|>\n    function_for_step_4_5_6()\n  \n  return(result)\n}\n```\n\nWe check that this performs as expected by comparing it's output to the values we already computed. Using the `all.equal` function, we see that it does!\n\n```{r, output=FALSE}\n  test=function_wrap(url1)\n```\n\n```{r}\n  all.equal(test[[1]], county)\n  all.equal(test[[2]], noncounty)\n  rm(test)\n```\n\nWith this function now in hand, we read in both the old data source and a new one accessible at [https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv](https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv).\n\n```{r, output=FALSE}\nurl2 <- \"https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv\"\n\ntibble1 <- function_wrap(url1)\ntibble2 <- function_wrap(url2)\n```\n\n```{r}\ntibble1\ntibble2\n```\n\n## Call Function And Combine Data\nWe then write a function to combine like data with like data (i.e. the county data from the first data source is combined with the county data from the second data source). We use the base function `rbind()` to do so, though we could also use the `dplyr` function `bind_rows()`.\n\n```{r}\nfunction_combine <- function(mytib1, mytib2) {\n  county_data=rbind(mytib1[[1]],mytib2[[1]])\n  non_county_data=rbind(mytib1[[2]], mytib2[[2]])\n  return(list(county_data, non_county_data))\n}\n\ncombined_data <- function_combine(tibble1,tibble2)\ncombined_data\n```\n\n\n## Writing Generic Functions For Summarizing\nWe now turn our attention to summarizing our results. We'd like to create functions that utilize the `ggplot2` package in the `tidyverse` to return nice visuals of our data.\n\n### Mean Enrollemnt By Division\nOur first function will summarize non-county data, returning the mean enrollment value by year for each division that the respective state is in. We only care about divisions, so exclude any values in our data that  aren't part of one by using `filter`. We want to plot our data for each division by year, so we use `group_by()` to do so. Finally, we want to find the mean value of each division each year, which we can grab with the `summarize()` function. We then plot this object using `ggplot()`, making small adjustments to make the output more visually appealing (such as centering the title with `theme(plot.title=element_text(hjust=0.5))` and removing `ggplots()` ugly default with ` theme_bw()`). \n\n```{r}\nplot_state <- function(mytibble, default_var_name=\"observed\") {\n  tmp=mytibble |>\n    filter(division != \"ERROR\") |>\n    group_by(division, survey_year) |>\n    summarize(mean_observed=mean(get(default_var_name)))\n  \n  ggplot(tmp, aes(x=survey_year, y=mean_observed, color=division)) +\n    geom_line() +\n    labs(x=\"Year\", \n         y=\"Mean Enrollemnt Value\", \n         color=\"Division\", \n         title=\"Mean Enrollment Value by Year and Division\") +\n    theme_bw() +\n    theme(plot.title=element_text(hjust=0.5))\n}\n```\n\nTo make sure the function works as expected, we pass in the output from our `combined_data()`.\n\n```{r}\nplot_state(combined_data[[2]])\n```\n### Mean Data By County\n\nWe want to create a similar function to deal with county data, this time with more flexibility. We'd like to be able to show how only the top (or bottom) counties in a given state change over time. We put in a few default values. For example, if no state is inputted, we also look at North Carolina, if no sort type is provided we always look at the top values, etc. The function first extracts the top/bottom counties in the specified state using normal `dplyr` functions, then filters the inputted tibble to just those counties, and finally plots how the values change over time in a similar way to our ``ggplot2` functions above.\n\n\n```{r}\nplot_county <- function(mytibble, \n                        default_var_name=\"observed\", \n                        default_state=\"NC\",  \n                        default_sort=\"top\", \n                        default_count=5){\n  \n  if (default_sort == \"top\") {\n    area_name_for_plot=mytibble |>\n      filter(state == default_state) |>\n      group_by(area_name) |>\n      summarize(mean_value = mean(get(default_var_name))) |>\n      arrange(desc(mean_value)) |>\n      slice(1:default_count) |>\n      pull(area_name)\n  } else if (default_sort == \"bottom\") {\n    area_name_for_plot=mytibble |>\n      filter(state == default_state) |>\n      group_by(area_name) |>\n      summarize(mean_value = mean(get(default_var_name))) |>\n      arrange(mean_value) |>\n      slice(1:default_count) |>\n      pull(area_name)\n  } \n  \n  plot_state=mytibble |>\n    filter(area_name %in% area_name_for_plot)\n  \n  ggplot(plot_state, aes(x = survey_year, y = get(default_var_name), color = area_name)) +\n    geom_line() +\n    labs(x = \"Year\",\n         y = \"Enrollment Value\",\n         color = \"Counties\",\n         title = \"Enrollment Value by Year in Counties Referred\") +\n    theme_bw() +\n    theme(plot.title=element_text(hjust=0.5))\n}\n```\n\nTo make sure it works as expected, we try it on one of our first datasets.\n\n\n```{r}\nplot_county(county)\n```\n\n\n## Put It Together\n\n### Add New Data\nIn addition to the two urls we already have, we would also like to explore four other data sources. We put these urls into a list, which we plan to loop through in the future.\n\n```{r}\nurl3=\"https://www4.stat.ncsu.edu/~online/datasets/PST01a.csv\"\nurl4=\"https://www4.stat.ncsu.edu/~online/datasets/PST01b.csv\"\nurl5=\"https://www4.stat.ncsu.edu/~online/datasets/PST01c.csv\"\nurl6=\"https://www4.stat.ncsu.edu/~online/datasets/PST01d.csv\"\n\nurl_list <- list(url1, url2,url3,url4,url5,url6)\nrm(url1,url2,url3,url4,url5,url6)\n```\n\nFor each url in our list, we apply our data processing function `function_wrap`. We create common names for the output of our data sources: `data1` for the first url (what we've previously called `census`), `data2` for the second, etc.\n\n```{r, output=FALSE}\nfor (i in 1:6) {\n  myvar=paste0(\"data\",i)\n  assign(myvar, function_wrap(url_list[[i]]))\n}\n\nrm(i, myvar)\n```\n\nWe then combine the data with our previously created `function_combine()`. We want to combine the first two urls and the last four urls.\n\n```{r}\nfirst_urls <- function_combine(data1,data2)\nsecond_urls <- function_combine(data3,\n  function_combine(data4,\n    function_combine(data5, data6)))\n\nrm(data1,data2,data3,data4,data5,data6)\n\nfirst_urls\nsecond_urls\n```\n\n### Testing Our Functions\n#### First Group Of URLs\n\nNow we test our functions! First on our first urls. We look at the divsion data with our `plot_state()` function.\n\n```{r}\nplot_state(first_urls[[2]])\n```\n\nThen we look at various iterations of our `plot_county()` funciton. First we specify the state to be “NC”, the group being the top, the number looked at being 20.\n\n```{r}\nplot_county(first_urls[[1]], \"observed\", \"NC\", \"top\", 20)\n```\nNext we specify the state to be South Carolina, the group to be the bottom, and the number being looked at to be 7.\n\n```{r}\nplot_county(first_urls[[1]], \"observed\", \"SC\", \"bottom\", 7)\n```\n\nWe can also just use our defaults.\n\n```{r}\nplot_county(first_urls[[1]])\n```\nAnd finally we can specify the state to be Pennsylvania, the group being the top, and the number looked at being 8.\n\n```{r}\nplot_county(first_urls[[1]], \"observed\", \"PA\", \"top\", 8)\n```\n\n#### Second Group Of URLs\n\nWe now move our attention to the second group of urls. We can examine the divisions with our `plot_state()` function.\n\n```{r}\nplot_state(second_urls[[2]])\n```\n\nWe can specify our state to be California, the group being the top, and the number looked at being 15 below.\n\n```{r}\nplot_county(second_urls[[1]], \"observed\", \"CA\", \"top\", 15)\n```\n\nAnoter example is to specify our state to be Texas, the group being the top, and the number being looked at 4 below. \n\n```{r}\nplot_county(second_urls[[1]], \"observed\", \"TX\", \"top\", 4)\n```\n\nWe can just use our defaults too.\n\n```{r}\nplot_county(second_urls[[1]])\n```\n\nFinally, we can specify the state to be New York, the group being the top, and the number being looked at to be 10.\n\n```{r}\nplot_county(second_urls[[1]], \"observed\", \"NY\", \"top\", 10)\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"ST558 Project 1 Quarto Doc.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.553","title":"ST558 Project 1","author":"Flaherty and Lu","editor":"visual"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}