{"title":"ST558 Project 1","markdown":{"yaml":{"title":"ST558 Project 1","author":"Flaherty and Lu","format":"html","editor":"visual"},"headingText":"Data Processing","containsRefs":false,"markdown":"\n\n\nWe are interested in various types of census data, and aim to create functions that return visuals of said data from inputs of either urls or csv files. To start, we look at a single file before generalizing.\n\nThe file was made available at <https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv>, where we download it locally and then loaded it into our R session. Since we are using R projects, and since we saved the download in the working directory for the project, we don't need to worry about specifying file paths. To start our analysis, we installed any packages we might need with `install.packages`, and call them here with `library()`.\n\n```{r, include=FALSE}\nlibrary(tidyverse)            \nlibrary(readxl)\n\n\ncensus=read_csv(\"EDU01a.csv\")       \n```\n\n### Initial Data Exploration\nTo get an initial glance at the data, we try normal summary functions. Since the output of these functions is so long, we admit it here. What is clear from the output is that without additional context for what the variables mean, the file contents would be very confusing.\n\n```{r, include=FALSE}\nstr(census)\nsummary(census)\n```\n\nLuckily we are given some of this information. The file contains census data from 2010, with distinct areas in each row, and census surveys in each column. The census surveys follow a code: the first three characters give the survey type (for example **AGE** in the `AGE010180D` code refers to age, while **EDU** in the  `EDU640180D` code refers to education), the next four give the type of value from the survey (for example **6401** in the `EDU640180D` code refers to years of school complete, while **0101** in the `EDU010189D` code refers to public school enrollment), and the next two give the year (for example the **89** in the `EDU010189D` code refers to 1989). There is no data from before 1910. \n\n\n### Data Manipulation And Wrangling\n#### Select, Reshape, And Rename\n\nAs is, the data is not in a great format for analysis. We want to filter down the data to just the columns we actually care about, and to put it in long format. That is, instead of a distinct area in each row with many different census types in the columns, we want to have just one record for each row, with an additional column added for the census code.\n\nTo choose the columns we want, ew use the `select()` function from the `tidyverse`. To keep our naming conventions consistent, we also want to `rename()` certain columns. Additionally, we want to transform our data structure so that the columns holding count data are put in a single column, and the data from those columns put in a new column called `observed`. We can do so with the `pivot_longer()` function. Putting all these steps together with the natural chaining operation `|>`, we can overwrite our object as follows: \n\n```{r}\ncensus=census |>                   \n  select(Area_name, STCOU, ends_with(\"D\")) |>\n  rename(area_name=Area_name) |>\n  pivot_longer(cols=ends_with(\"D\"),\n               names_to=\"code\",    \n               values_to=\"observed\")\n```\n\n#### Break Apart Census Code\nIn general, we want the smallest piece of data stored in it's own column. Specific to this file, the census code encodes a lot of information which we'd like to break up so that we can more easily filter it in the future. \n\nOne way to do so is to extract the year from which the survey was conducted on, and store the year and census type in their own columns. Note that direct inspection on a csv file giving information on the variables, namely using ``=SORT(UNIQUE(RIGHT(range_of_cells, 4)))`, showed that no data existed prior to 1910-- any two-digit code less than 10 will be from the 2000s.\n\nSince we are in the `tidyverse` already, it makes sense to utilize the `stringr` package to deal with these strings. Within that packages, `str_sub` extracts parts of a string. Since we know the first 7 characters of our string give the survey type, we can directly extract those to form a new column. Since we know the next two characters of our string give the year, we can append the relevant first two digits to make a year. We have already explained that no data prior to 1910 exists, so know that any data with a year value under 10 will be from the 2000s. \n\n```{r, output=FALSE}\nsurvey_type=str_sub(census$code, start=1, end=7)\n\nyy=as.numeric(str_sub(census$code, start=8, end=9))\nrange(yy)                          #87-96 so all from 90s here, but want to make robust#  \nsurvey_year=as.numeric(ifelse(yy<=10,                        \n                              paste0(\"200\", yy),\n                              paste0(\"19\", yy)))\n\ncensus=census |>\n  mutate(survey_type=survey_type, survey_year=survey_year) |>\n  select(area_name, STCOU, survey_type, survey_year, observed)\n\nrm(yy, survey_type, survey_year)                             #no need to keep#\n```\n#### Break Into County Vs. Non-County Data    \n\nIn keeping with the above, we'd like to get more granular into our data, specifying the county name when available. To do so, we again rely on the `stringr` package and perform similar operations to the above. \n\nWe first get a sense of the naming patters in our `area_name` column.\n\n```{r}\nunique(census$area_name)[1:10]\n```\n\nNotice that commas exist in areas which have the county specified (like \"Autauga, AL\"), but there are no commas in areas without county-level data (like \"ALABAMA\"). We can split our existing `census` tibble into two different tibbles, one with county-level data and one without, by searching for the rows in the tibble which have a comma. The `str_locate()` function in the `stringr` package does the trick, taking in our vector of `area_name`'s, searching for the comma, and returning a matrix giving the starting and ending character of where the comma exists. Since a comma is only one character, we only need one of these columns, and so return just the first column from our matrix. \n\n```{r}\na=str_locate(census$area_name, \",\")[,1]            #dummy object, no commas in non-county#\nnoncounty=census[which(is.na(a)),]                 #keep non-county data together#\ncounty=census[which(!is.na(a)),]                   #keep county data together#\nrm(a)                                              #no need to keep#\n```\n\nWe can double check that this split worked as expected with `unique` from base R.\n\n```{r}\nunique(noncounty$area_name)                        \nunique(county$area_name)[1:50]\n```\n\nAfter verifying that the split worked as intended, we add a class to each tibble, overwriting the previous one.\n\n```{r}\nclass(county)=c(\"county\", class(county))           \nclass(noncounty)=c(\"state\", class(noncounty))      \n```\n\n#### Classifying States And Divisions\nWith the distinct tables now in hand, we want to break up the `area_name` to both the county and state in the case of the `county` data, and to include the division in the case of the `noncounty` data. \n\nIn the `county` data, we are just extracting the last two characters of the string for the state abbreviation, and all parts of the string less the last four for the county (two for the state abbreviation, one for the space, one for the comma). We can do this succinctly with the same `str_sub` function, utilizing the `nchar` function in the process (which logically returns the number of characters a string has).\n\n```{r}\ncounty=county |>\n  mutate(state=str_sub(area_name, nchar(county$area_name) - 1, nchar(county$area_name)),\n         district=str_sub(area_name, 1, nchar(county$area_name)-4)) |>\n  select(-area_name) |>\n  select(state, district, everything())\n```\n\nIn the `noncounty` data, we are adding a variable corresponding to the state's classification of divisions found at [https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States?useskin=vector](https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States?useskin=vector). We store these classifications in a list called `region`. Note that the syntax of the strings in our list was choosen to follow the syntax of the names which exist in our `noncounty$area_name`.\n\n```{r}\nd1=c(\"CONNECTICUT\", \"MAINE\", \"MASSACHUSETTS\", \"NEW HAMPSHIRE\", \"RHODE ISLAND\", \"VERMONT\")\nd2=c(\"NEW JERSEY\", \"NEW YORK\", \"PENNSYLVANIA\")\nd3=c(\"ILLINOIS\", \"INDIANA\", \"MICHIGAN\", \"OHIO\", \"WISCONSIN\")\nd4=c(\"IOWA\", \"KANSAS\", \"MINNESOTA\", \"MISSOURI\", \"NEBRASKA\", \"NORTH DAKOTA\", \"SOUTH DAKOTA\")\nd5=c(\"DELAWARE\", \"FLORIDA\", \"GEORGIA\", \"MARYLAND\", \"NORTH CAROLINA\", \"SOUTH CAROLINA\", \"VIRGINIA\", \"DISTRICT OF COLUMBIA\", \"District of Columbia\", \"WEST VIRGINIA\")\nd6=c(\"ALABAMA\", \"KENTUCKY\", \"MISSISSIPPI\", \"TENNESSEE\")\nd7=c(\"ARKANSAS\", \"LOUISIANA\", \"OKLAHOMA\", \"TEXAS\")\nd8=c(\"ARIZONA\", \"COLORADO\", \"IDAHO\", \"MONTANA\", \"NEVADA\", \"NEW MEXICO\", \"UTAH\", \"WYOMING\")\nd9=c(\"ALASKA\", \"CALIFORNIA\", \"HAWAII\", \"OREGON\", \"WASHINGTON\")\n\nregion=list(d1,d2,d3,d4,d5,d6,d7,d8,d9)\n```\n\nNext we initialize the `division` vector we want to add, and create a `for` loop to find it's values. The strategy in the loop is to look at each row of our `noncounty` data, then cycle through each element of the `region` list to find which column contains the state we are looking for. To do so, we utilize a `while` loop, only iterating to the next list element if our `area_name` wasn't in the previous list element (hence the use of the negation operator). Note the use of `[[]]` as opposed to `[]`-- we use the `%in%` function to check whether our row's `area_name` is in a *vector*. \n\n\n```{r}\ndivision=vector()\n\nfor (i in 1:nrow(noncounty)) {\n  j=1\n  while(j<=length(region) && !(noncounty$area_name[i] %in% region[[j]])) {\n    j=j+1\n  }\n  division[i]=ifelse(j<=length(region), j, \"ERROR\")\n}\n\nnoncounty$division=division\nnoncounty=noncounty |> select(area_name, division, everything())\n\nrm(d1,d2,d3,d4,d5,d6,d7,d8,d9,region,division,i,j)      #keep environment clean#\n```\n\n\n## Function Writing\n\nWe want to create functions that can do all the above with just the input of a file path or url. \n\nIn the first step to the data processing section above, we looked at selecting, renaming, and reshaping our data. We create a function that performs these steps below, essentially just copying our steps into a user-defined function (udf) called  `function_for_step_1_2`. Note that the input to the function must be a string (i.e. the url must be in quotes).\n\n\n```{r}\nfunction_for_step_1_2=function(url, default_var_name=\"observed\") {\n  tmp=read_csv(url) |>\n    select(Area_name, STCOU, ends_with(\"D\")) |>\n    rename(area_name = Area_name) |>   \n    pivot_longer(cols = ends_with(\"D\"),\n                 names_to = \"code\",\n                 values_to = default_var_name)\n  return(tmp)\n}\n```\n\nIn the third step to the data processing section above, we looked at parsing strings, specifically breaking up the census code into the survey type and survey year. We again put the process we followed into a single function `function_for_step_3` that takes as input the output from `function_for_step_1_2`. Note that we must have renamed the census codes to `code` upon reshaping the data in `function_for_step_1_2` for this to work. \n\n\n```{r}\nfunction_for_step_3=function(mytibble) {\n  survey_type=str_sub(mytibble$code, start=1, end=7)\n  yy=as.numeric(str_sub(mytibble$code, start=8, end=9))\n  survey_year=as.numeric(ifelse(yy<=10,                        \n                                paste0(\"200\", yy),\n                                paste0(\"19\", yy)))\n  tmp=mytibble |>\n    mutate(survey_type=survey_type, survey_year=survey_year) |>\n    select(area_name, STCOU, survey_type, survey_year, observed)\n  return(tmp)\n}\n```\n\nSkipping a step, in the fifth step to the data processing section above, we looked at parsing our `area_name` into separate variables for the `state` and `county`. We now put this process into a single function `function_for_step_5`. \n\n```{r}\nfunction_for_step_5=function(mytibble) {\n  tmp=mytibble |> \n    mutate(state=str_sub(area_name, nchar(mytibble$area_name) - 1, nchar(mytibble$area_name)),\n           district=str_sub(area_name, 1, nchar(mytibble$area_name)-4)) |>\n    select(-area_name) |>\n    select(state, district, everything())\n  return(tmp)\n}\n```\n\nIn the sixth step to the data processing section above, we looked at adding the division of our `area_name` to the tibble. We now put this process into a single function `function_for_step_6`. \n\n```{r}\nfunction_for_step_6=function(mytibble) {\n  d1=c(\"CONNECTICUT\", \"MAINE\", \"MASSACHUSETTS\", \"NEW HAMPSHIRE\", \"RHODE ISLAND\", \"VERMONT\")\n  d2=c(\"NEW JERSEY\", \"NEW YORK\", \"PENNSYLVANIA\")\n  d3=c(\"ILLINOIS\", \"INDIANA\", \"MICHIGAN\", \"OHIO\", \"WISCONSIN\")\n  d4=c(\"IOWA\", \"KANSAS\", \"MINNESOTA\", \"MISSOURI\", \"NEBRASKA\", \"NORTH DAKOTA\", \"SOUTH DAKOTA\")\n  d5=c(\"DELAWARE\", \"FLORIDA\", \"GEORGIA\", \"MARYLAND\", \"NORTH CAROLINA\", \"SOUTH CAROLINA\", \"VIRGINIA\", \"DISTRICT OF COLUMBIA\", \"District of Columbia\", \"WEST VIRGINIA\")\n  d6=c(\"ALABAMA\", \"KENTUCKY\", \"MISSISSIPPI\", \"TENNESSEE\")\n  d7=c(\"ARKANSAS\", \"LOUISIANA\", \"OKLAHOMA\", \"TEXAS\")\n  d8=c(\"ARIZONA\", \"COLORADO\", \"IDAHO\", \"MONTANA\", \"NEVADA\", \"NEW MEXICO\", \"UTAH\", \"WYOMING\")\n  d9=c(\"ALASKA\", \"CALIFORNIA\", \"HAWAII\", \"OREGON\", \"WASHINGTON\")\n  \n  region=list(d1,d2,d3,d4,d5,d6,d7,d8,d9)\n  division=vector()\n  \n  for (i in 1:nrow(mytibble)) {\n    j=1\n    \n    while(j<=length(region) && !(mytibble$area_name[i] %in% region[[j]])) {\n      j=j+1\n    }\n    \n    division[i]=ifelse(j<=length(region), j, \"ERROR\")\n  }\n  mytibble$division=division\n  \n  tmp=mytibble |>\n    select(area_name, division, everything())\n   return(tmp) \n}\n```\n\nWe now return to our skipped fourth step, breaking the data into county and non-county data. Our function just copies our previous procedure in the data prcessing section, and then applies our `function_for_step_5` and `function_for_step_6` to the split data. We return a list whose first element is our `county` tibble and whose second element is our `noncounty` tibble.\n\n```{r}\nfunction_for_step_4_5_6=function(mytibble) {\n  a=str_locate(mytibble$area_name, \",\")[,1]            \n  noncounty=mytibble[which(is.na(a)),]                 \n  county=mytibble[which(!is.na(a)),]\n  \n  class(county)=c(\"county\", class(county))           \n  class(noncounty)=c(\"state\", class(noncounty))      \n  \n  county=function_for_step_5(county)\n  noncounty=function_for_step_6(noncounty)\n  \n  return(list(county,noncounty))\n}\n```\n\nFinally, we create a single wrapper function that brings all of the above functions together.\n\n```{r}\nmyfunction=function(url, default_var_name=\"\") {\n  result=function_for_step_1_2(url, default_var_name) |>\n    function_for_step_3()|>\n    function_for_step_4_5_6()\n  \n  return(result)\n}\n```\n\nWe check that this performs as expected by comparing it's output to the values we already computed. Using the `all.equal` function, we see that it does!\n\n```{r}\ntest=myfunction(\"https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv\", \"observed\")\nall.equal(test[[1]], county)\nall.equal(test[[2]], noncounty)\nrm(test)\n```","srcMarkdownNoYaml":"\n\n## Data Processing\n\nWe are interested in various types of census data, and aim to create functions that return visuals of said data from inputs of either urls or csv files. To start, we look at a single file before generalizing.\n\nThe file was made available at <https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv>, where we download it locally and then loaded it into our R session. Since we are using R projects, and since we saved the download in the working directory for the project, we don't need to worry about specifying file paths. To start our analysis, we installed any packages we might need with `install.packages`, and call them here with `library()`.\n\n```{r, include=FALSE}\nlibrary(tidyverse)            \nlibrary(readxl)\n\n\ncensus=read_csv(\"EDU01a.csv\")       \n```\n\n### Initial Data Exploration\nTo get an initial glance at the data, we try normal summary functions. Since the output of these functions is so long, we admit it here. What is clear from the output is that without additional context for what the variables mean, the file contents would be very confusing.\n\n```{r, include=FALSE}\nstr(census)\nsummary(census)\n```\n\nLuckily we are given some of this information. The file contains census data from 2010, with distinct areas in each row, and census surveys in each column. The census surveys follow a code: the first three characters give the survey type (for example **AGE** in the `AGE010180D` code refers to age, while **EDU** in the  `EDU640180D` code refers to education), the next four give the type of value from the survey (for example **6401** in the `EDU640180D` code refers to years of school complete, while **0101** in the `EDU010189D` code refers to public school enrollment), and the next two give the year (for example the **89** in the `EDU010189D` code refers to 1989). There is no data from before 1910. \n\n\n### Data Manipulation And Wrangling\n#### Select, Reshape, And Rename\n\nAs is, the data is not in a great format for analysis. We want to filter down the data to just the columns we actually care about, and to put it in long format. That is, instead of a distinct area in each row with many different census types in the columns, we want to have just one record for each row, with an additional column added for the census code.\n\nTo choose the columns we want, ew use the `select()` function from the `tidyverse`. To keep our naming conventions consistent, we also want to `rename()` certain columns. Additionally, we want to transform our data structure so that the columns holding count data are put in a single column, and the data from those columns put in a new column called `observed`. We can do so with the `pivot_longer()` function. Putting all these steps together with the natural chaining operation `|>`, we can overwrite our object as follows: \n\n```{r}\ncensus=census |>                   \n  select(Area_name, STCOU, ends_with(\"D\")) |>\n  rename(area_name=Area_name) |>\n  pivot_longer(cols=ends_with(\"D\"),\n               names_to=\"code\",    \n               values_to=\"observed\")\n```\n\n#### Break Apart Census Code\nIn general, we want the smallest piece of data stored in it's own column. Specific to this file, the census code encodes a lot of information which we'd like to break up so that we can more easily filter it in the future. \n\nOne way to do so is to extract the year from which the survey was conducted on, and store the year and census type in their own columns. Note that direct inspection on a csv file giving information on the variables, namely using ``=SORT(UNIQUE(RIGHT(range_of_cells, 4)))`, showed that no data existed prior to 1910-- any two-digit code less than 10 will be from the 2000s.\n\nSince we are in the `tidyverse` already, it makes sense to utilize the `stringr` package to deal with these strings. Within that packages, `str_sub` extracts parts of a string. Since we know the first 7 characters of our string give the survey type, we can directly extract those to form a new column. Since we know the next two characters of our string give the year, we can append the relevant first two digits to make a year. We have already explained that no data prior to 1910 exists, so know that any data with a year value under 10 will be from the 2000s. \n\n```{r, output=FALSE}\nsurvey_type=str_sub(census$code, start=1, end=7)\n\nyy=as.numeric(str_sub(census$code, start=8, end=9))\nrange(yy)                          #87-96 so all from 90s here, but want to make robust#  \nsurvey_year=as.numeric(ifelse(yy<=10,                        \n                              paste0(\"200\", yy),\n                              paste0(\"19\", yy)))\n\ncensus=census |>\n  mutate(survey_type=survey_type, survey_year=survey_year) |>\n  select(area_name, STCOU, survey_type, survey_year, observed)\n\nrm(yy, survey_type, survey_year)                             #no need to keep#\n```\n#### Break Into County Vs. Non-County Data    \n\nIn keeping with the above, we'd like to get more granular into our data, specifying the county name when available. To do so, we again rely on the `stringr` package and perform similar operations to the above. \n\nWe first get a sense of the naming patters in our `area_name` column.\n\n```{r}\nunique(census$area_name)[1:10]\n```\n\nNotice that commas exist in areas which have the county specified (like \"Autauga, AL\"), but there are no commas in areas without county-level data (like \"ALABAMA\"). We can split our existing `census` tibble into two different tibbles, one with county-level data and one without, by searching for the rows in the tibble which have a comma. The `str_locate()` function in the `stringr` package does the trick, taking in our vector of `area_name`'s, searching for the comma, and returning a matrix giving the starting and ending character of where the comma exists. Since a comma is only one character, we only need one of these columns, and so return just the first column from our matrix. \n\n```{r}\na=str_locate(census$area_name, \",\")[,1]            #dummy object, no commas in non-county#\nnoncounty=census[which(is.na(a)),]                 #keep non-county data together#\ncounty=census[which(!is.na(a)),]                   #keep county data together#\nrm(a)                                              #no need to keep#\n```\n\nWe can double check that this split worked as expected with `unique` from base R.\n\n```{r}\nunique(noncounty$area_name)                        \nunique(county$area_name)[1:50]\n```\n\nAfter verifying that the split worked as intended, we add a class to each tibble, overwriting the previous one.\n\n```{r}\nclass(county)=c(\"county\", class(county))           \nclass(noncounty)=c(\"state\", class(noncounty))      \n```\n\n#### Classifying States And Divisions\nWith the distinct tables now in hand, we want to break up the `area_name` to both the county and state in the case of the `county` data, and to include the division in the case of the `noncounty` data. \n\nIn the `county` data, we are just extracting the last two characters of the string for the state abbreviation, and all parts of the string less the last four for the county (two for the state abbreviation, one for the space, one for the comma). We can do this succinctly with the same `str_sub` function, utilizing the `nchar` function in the process (which logically returns the number of characters a string has).\n\n```{r}\ncounty=county |>\n  mutate(state=str_sub(area_name, nchar(county$area_name) - 1, nchar(county$area_name)),\n         district=str_sub(area_name, 1, nchar(county$area_name)-4)) |>\n  select(-area_name) |>\n  select(state, district, everything())\n```\n\nIn the `noncounty` data, we are adding a variable corresponding to the state's classification of divisions found at [https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States?useskin=vector](https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States?useskin=vector). We store these classifications in a list called `region`. Note that the syntax of the strings in our list was choosen to follow the syntax of the names which exist in our `noncounty$area_name`.\n\n```{r}\nd1=c(\"CONNECTICUT\", \"MAINE\", \"MASSACHUSETTS\", \"NEW HAMPSHIRE\", \"RHODE ISLAND\", \"VERMONT\")\nd2=c(\"NEW JERSEY\", \"NEW YORK\", \"PENNSYLVANIA\")\nd3=c(\"ILLINOIS\", \"INDIANA\", \"MICHIGAN\", \"OHIO\", \"WISCONSIN\")\nd4=c(\"IOWA\", \"KANSAS\", \"MINNESOTA\", \"MISSOURI\", \"NEBRASKA\", \"NORTH DAKOTA\", \"SOUTH DAKOTA\")\nd5=c(\"DELAWARE\", \"FLORIDA\", \"GEORGIA\", \"MARYLAND\", \"NORTH CAROLINA\", \"SOUTH CAROLINA\", \"VIRGINIA\", \"DISTRICT OF COLUMBIA\", \"District of Columbia\", \"WEST VIRGINIA\")\nd6=c(\"ALABAMA\", \"KENTUCKY\", \"MISSISSIPPI\", \"TENNESSEE\")\nd7=c(\"ARKANSAS\", \"LOUISIANA\", \"OKLAHOMA\", \"TEXAS\")\nd8=c(\"ARIZONA\", \"COLORADO\", \"IDAHO\", \"MONTANA\", \"NEVADA\", \"NEW MEXICO\", \"UTAH\", \"WYOMING\")\nd9=c(\"ALASKA\", \"CALIFORNIA\", \"HAWAII\", \"OREGON\", \"WASHINGTON\")\n\nregion=list(d1,d2,d3,d4,d5,d6,d7,d8,d9)\n```\n\nNext we initialize the `division` vector we want to add, and create a `for` loop to find it's values. The strategy in the loop is to look at each row of our `noncounty` data, then cycle through each element of the `region` list to find which column contains the state we are looking for. To do so, we utilize a `while` loop, only iterating to the next list element if our `area_name` wasn't in the previous list element (hence the use of the negation operator). Note the use of `[[]]` as opposed to `[]`-- we use the `%in%` function to check whether our row's `area_name` is in a *vector*. \n\n\n```{r}\ndivision=vector()\n\nfor (i in 1:nrow(noncounty)) {\n  j=1\n  while(j<=length(region) && !(noncounty$area_name[i] %in% region[[j]])) {\n    j=j+1\n  }\n  division[i]=ifelse(j<=length(region), j, \"ERROR\")\n}\n\nnoncounty$division=division\nnoncounty=noncounty |> select(area_name, division, everything())\n\nrm(d1,d2,d3,d4,d5,d6,d7,d8,d9,region,division,i,j)      #keep environment clean#\n```\n\n\n## Function Writing\n\nWe want to create functions that can do all the above with just the input of a file path or url. \n\nIn the first step to the data processing section above, we looked at selecting, renaming, and reshaping our data. We create a function that performs these steps below, essentially just copying our steps into a user-defined function (udf) called  `function_for_step_1_2`. Note that the input to the function must be a string (i.e. the url must be in quotes).\n\n\n```{r}\nfunction_for_step_1_2=function(url, default_var_name=\"observed\") {\n  tmp=read_csv(url) |>\n    select(Area_name, STCOU, ends_with(\"D\")) |>\n    rename(area_name = Area_name) |>   \n    pivot_longer(cols = ends_with(\"D\"),\n                 names_to = \"code\",\n                 values_to = default_var_name)\n  return(tmp)\n}\n```\n\nIn the third step to the data processing section above, we looked at parsing strings, specifically breaking up the census code into the survey type and survey year. We again put the process we followed into a single function `function_for_step_3` that takes as input the output from `function_for_step_1_2`. Note that we must have renamed the census codes to `code` upon reshaping the data in `function_for_step_1_2` for this to work. \n\n\n```{r}\nfunction_for_step_3=function(mytibble) {\n  survey_type=str_sub(mytibble$code, start=1, end=7)\n  yy=as.numeric(str_sub(mytibble$code, start=8, end=9))\n  survey_year=as.numeric(ifelse(yy<=10,                        \n                                paste0(\"200\", yy),\n                                paste0(\"19\", yy)))\n  tmp=mytibble |>\n    mutate(survey_type=survey_type, survey_year=survey_year) |>\n    select(area_name, STCOU, survey_type, survey_year, observed)\n  return(tmp)\n}\n```\n\nSkipping a step, in the fifth step to the data processing section above, we looked at parsing our `area_name` into separate variables for the `state` and `county`. We now put this process into a single function `function_for_step_5`. \n\n```{r}\nfunction_for_step_5=function(mytibble) {\n  tmp=mytibble |> \n    mutate(state=str_sub(area_name, nchar(mytibble$area_name) - 1, nchar(mytibble$area_name)),\n           district=str_sub(area_name, 1, nchar(mytibble$area_name)-4)) |>\n    select(-area_name) |>\n    select(state, district, everything())\n  return(tmp)\n}\n```\n\nIn the sixth step to the data processing section above, we looked at adding the division of our `area_name` to the tibble. We now put this process into a single function `function_for_step_6`. \n\n```{r}\nfunction_for_step_6=function(mytibble) {\n  d1=c(\"CONNECTICUT\", \"MAINE\", \"MASSACHUSETTS\", \"NEW HAMPSHIRE\", \"RHODE ISLAND\", \"VERMONT\")\n  d2=c(\"NEW JERSEY\", \"NEW YORK\", \"PENNSYLVANIA\")\n  d3=c(\"ILLINOIS\", \"INDIANA\", \"MICHIGAN\", \"OHIO\", \"WISCONSIN\")\n  d4=c(\"IOWA\", \"KANSAS\", \"MINNESOTA\", \"MISSOURI\", \"NEBRASKA\", \"NORTH DAKOTA\", \"SOUTH DAKOTA\")\n  d5=c(\"DELAWARE\", \"FLORIDA\", \"GEORGIA\", \"MARYLAND\", \"NORTH CAROLINA\", \"SOUTH CAROLINA\", \"VIRGINIA\", \"DISTRICT OF COLUMBIA\", \"District of Columbia\", \"WEST VIRGINIA\")\n  d6=c(\"ALABAMA\", \"KENTUCKY\", \"MISSISSIPPI\", \"TENNESSEE\")\n  d7=c(\"ARKANSAS\", \"LOUISIANA\", \"OKLAHOMA\", \"TEXAS\")\n  d8=c(\"ARIZONA\", \"COLORADO\", \"IDAHO\", \"MONTANA\", \"NEVADA\", \"NEW MEXICO\", \"UTAH\", \"WYOMING\")\n  d9=c(\"ALASKA\", \"CALIFORNIA\", \"HAWAII\", \"OREGON\", \"WASHINGTON\")\n  \n  region=list(d1,d2,d3,d4,d5,d6,d7,d8,d9)\n  division=vector()\n  \n  for (i in 1:nrow(mytibble)) {\n    j=1\n    \n    while(j<=length(region) && !(mytibble$area_name[i] %in% region[[j]])) {\n      j=j+1\n    }\n    \n    division[i]=ifelse(j<=length(region), j, \"ERROR\")\n  }\n  mytibble$division=division\n  \n  tmp=mytibble |>\n    select(area_name, division, everything())\n   return(tmp) \n}\n```\n\nWe now return to our skipped fourth step, breaking the data into county and non-county data. Our function just copies our previous procedure in the data prcessing section, and then applies our `function_for_step_5` and `function_for_step_6` to the split data. We return a list whose first element is our `county` tibble and whose second element is our `noncounty` tibble.\n\n```{r}\nfunction_for_step_4_5_6=function(mytibble) {\n  a=str_locate(mytibble$area_name, \",\")[,1]            \n  noncounty=mytibble[which(is.na(a)),]                 \n  county=mytibble[which(!is.na(a)),]\n  \n  class(county)=c(\"county\", class(county))           \n  class(noncounty)=c(\"state\", class(noncounty))      \n  \n  county=function_for_step_5(county)\n  noncounty=function_for_step_6(noncounty)\n  \n  return(list(county,noncounty))\n}\n```\n\nFinally, we create a single wrapper function that brings all of the above functions together.\n\n```{r}\nmyfunction=function(url, default_var_name=\"\") {\n  result=function_for_step_1_2(url, default_var_name) |>\n    function_for_step_3()|>\n    function_for_step_4_5_6()\n  \n  return(result)\n}\n```\n\nWe check that this performs as expected by comparing it's output to the values we already computed. Using the `all.equal` function, we see that it does!\n\n```{r}\ntest=myfunction(\"https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv\", \"observed\")\nall.equal(test[[1]], county)\nall.equal(test[[2]], noncounty)\nrm(test)\n```"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"ST558 Project 1 Quarto Doc.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.553","title":"ST558 Project 1","author":"Flaherty and Lu","editor":"visual"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}