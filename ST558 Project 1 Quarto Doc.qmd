---
title: "ST558 Project 1"
author: "Flaherty and Lu"
format: html
editor: visual
---

## Data Processing

We are interested in various types of census data, and aim to create functions that return visuals of said data from inputs of either urls or csv files. To start, we look at a single file before generalizing.

The file was made available at <https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv>. We could either download this locally and save it to our ression, accessing it through the working directory of our projects, or grab the data directly from the url. We opt for the latter. To start our analysis, we installed any packages we might need with `install.packages`, and call them here with `library()`.

```{r, include=FALSE}
library(tidyverse)            
library(readxl)

census=read_csv("https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv")
```

### Initial Data Exploration
To get an initial glance at the data, we try normal summary functions. Since the output of these functions is so long, we admit it here. What is clear from the output is that without additional context for what the variables mean, the file contents would be very confusing.

```{r, include=FALSE}
str(census)
summary(census)
```

Luckily we are given some of this information. The file contains census data from 2010, with distinct areas in each row, and census surveys in each column. The census surveys follow a code: the first three characters give the survey type (for example **AGE** in the `AGE010180D` code refers to age, while **EDU** in the  `EDU640180D` code refers to education), the next four give the type of value from the survey (for example **6401** in the `EDU640180D` code refers to years of school complete, while **0101** in the `EDU010189D` code refers to public school enrollment), and the next two give the year (for example the **89** in the `EDU010189D` code refers to 1989). There is no data from before 1910. 


### Data Manipulation And Wrangling
#### Select, Reshape, And Rename

As is, the data is not in a great format for analysis. We want to filter down the data to just the columns we actually care about, and to put it in long format. That is, instead of a distinct area in each row with many different census types in the columns, we want to have just one record for each row, with an additional column added for the census code.

To choose the columns we want, ew use the `select()` function from the `tidyverse`. To keep our naming conventions consistent, we also want to `rename()` certain columns. Additionally, we want to transform our data structure so that the columns holding count data are put in a single column, and the data from those columns put in a new column called `observed`. We can do so with the `pivot_longer()` function. Putting all these steps together with the natural chaining operation `|>`, we can overwrite our object as follows: 

```{r}
census=census |>                   
  select(Area_name, STCOU, ends_with("D")) |>
  rename(area_name=Area_name) |>
  pivot_longer(cols=ends_with("D"),
               names_to="code",    
               values_to="observed")
```

#### Break Apart Census Code
In general, we want the smallest piece of data stored in it's own column. Specific to this file, the census code encodes a lot of information which we'd like to break up so that we can more easily filter it in the future. 

One way to do so is to extract the year from which the survey was conducted on, and store the year and census type in their own columns. Note that direct inspection on a csv file giving information on the variables, namely using ``=SORT(UNIQUE(RIGHT(range_of_cells, 4)))`, showed that no data existed prior to 1910-- any two-digit code less than 10 will be from the 2000s.

Since we are in the `tidyverse` already, it makes sense to utilize the `stringr` package to deal with these strings. Within that packages, `str_sub` extracts parts of a string. Since we know the first 7 characters of our string give the survey type, we can directly extract those to form a new column. Since we know the next two characters of our string give the year, we can append the relevant first two digits to make a year. We have already explained that no data prior to 1910 exists, so know that any data with a year value under 10 will be from the 2000s. 

```{r, output=FALSE}
survey_type=str_sub(census$code, start=1, end=7)

yy=as.numeric(str_sub(census$code, start=8, end=9))
range(yy)                          #87-96 so all from 90s here, but want to make robust#  
survey_year=as.numeric(ifelse(yy<=10,                        
                              paste0("200", yy),
                              paste0("19", yy)))

census=census |>
  mutate(survey_type=survey_type, survey_year=survey_year) |>
  select(area_name, STCOU, survey_type, survey_year, observed)

rm(yy, survey_type, survey_year)                             #no need to keep#
```
#### Break Into County Vs. Non-County Data    

In keeping with the above, we'd like to get more granular into our data, specifying the county name when available. To do so, we again rely on the `stringr` package and perform similar operations to the above. 

We first get a sense of the naming patters in our `area_name` column.

```{r}
unique(census$area_name)[1:10]
```

Notice that commas exist in areas which have the county specified (like "Autauga, AL"), but there are no commas in areas without county-level data (like "ALABAMA"). We can split our existing `census` tibble into two different tibbles, one with county-level data and one without, by searching for the rows in the tibble which have a comma. The `str_locate()` function in the `stringr` package does the trick, taking in our vector of `area_name`'s, searching for the comma, and returning a matrix giving the starting and ending character of where the comma exists. Since a comma is only one character, we only need one of these columns, and so return just the first column from our matrix. 

```{r}
a=str_locate(census$area_name, ",")[,1]            #dummy object, no commas in non-county#
noncounty=census[which(is.na(a)),]                 #keep non-county data together#
county=census[which(!is.na(a)),]                   #keep county data together#
rm(a)                                              #no need to keep#
```

We can double check that this split worked as expected with `unique` from base R.

```{r}
unique(noncounty$area_name)                        
unique(county$area_name)[1:50]
```

After verifying that the split worked as intended, we add a class to each tibble, overwriting the previous one.

```{r}
class(county)=c("county", class(county))           
class(noncounty)=c("state", class(noncounty))      
```

#### Classifying States And Divisions
With the distinct tables now in hand, we want to break up the `area_name` to both the county and state in the case of the `county` data, and to include the division in the case of the `noncounty` data. 

In the `county` data, we are just extracting the last two characters of the string for the state abbreviation, and all parts of the string less the last four for the county (two for the state abbreviation, one for the space, one for the comma). We can do this succinctly with the same `str_sub` function, utilizing the `nchar` function in the process (which logically returns the number of characters a string has).

```{r}
county=county |>
  mutate(state=str_sub(area_name, nchar(county$area_name) - 1, nchar(county$area_name)),
         district=str_sub(area_name, 1, nchar(county$area_name)-4)) |>
  select(-area_name) |>
  select(state, district, everything())
```

In the `noncounty` data, we are adding a variable corresponding to the state's classification of divisions found at [https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States?useskin=vector](https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States?useskin=vector). We store these classifications in a list called `region`. Note that the syntax of the strings in our list was choosen to follow the syntax of the names which exist in our `noncounty$area_name`.

```{r}
d1=c("CONNECTICUT", "MAINE", "MASSACHUSETTS", "NEW HAMPSHIRE", "RHODE ISLAND", "VERMONT")
d2=c("NEW JERSEY", "NEW YORK", "PENNSYLVANIA")
d3=c("ILLINOIS", "INDIANA", "MICHIGAN", "OHIO", "WISCONSIN")
d4=c("IOWA", "KANSAS", "MINNESOTA", "MISSOURI", "NEBRASKA", "NORTH DAKOTA", "SOUTH DAKOTA")
d5=c("DELAWARE", "FLORIDA", "GEORGIA", "MARYLAND", "NORTH CAROLINA", "SOUTH CAROLINA", "VIRGINIA", "DISTRICT OF COLUMBIA", "District of Columbia", "WEST VIRGINIA")
d6=c("ALABAMA", "KENTUCKY", "MISSISSIPPI", "TENNESSEE")
d7=c("ARKANSAS", "LOUISIANA", "OKLAHOMA", "TEXAS")
d8=c("ARIZONA", "COLORADO", "IDAHO", "MONTANA", "NEVADA", "NEW MEXICO", "UTAH", "WYOMING")
d9=c("ALASKA", "CALIFORNIA", "HAWAII", "OREGON", "WASHINGTON")

region=list(d1,d2,d3,d4,d5,d6,d7,d8,d9)
```

Next we initialize the `division` vector we want to add, and create a `for` loop to find it's values. The strategy in the loop is to look at each row of our `noncounty` data, then cycle through each element of the `region` list to find which column contains the state we are looking for. To do so, we utilize a `while` loop, only iterating to the next list element if our `area_name` wasn't in the previous list element (hence the use of the negation operator). Note the use of `[[]]` as opposed to `[]`-- we use the `%in%` function to check whether our row's `area_name` is in a *vector*. 


```{r}
division=vector()

for (i in 1:nrow(noncounty)) {
  j=1
  while(j<=length(region) && !(noncounty$area_name[i] %in% region[[j]])) {
    j=j+1
  }
  division[i]=ifelse(j<=length(region), j, "ERROR")
}

noncounty$division=division
noncounty=noncounty |> select(area_name, division, everything())

rm(d1,d2,d3,d4,d5,d6,d7,d8,d9,region,division,i,j)      #keep environment clean#
```


## Function Writing

We want to create functions that can do all the above with just the input of a file path or url. 

In the first step to the data processing section above, we looked at selecting, renaming, and reshaping our data. We create a function that performs these steps below, essentially just copying our steps into a user-defined function (udf) called  `function_for_step_1_2`. Note that the input to the function must be a string (i.e. the url must be in quotes).


```{r}
function_for_step_1_2=function(url, default_var_name="observed") {
  tmp=read_csv(url) |>
    select(Area_name, STCOU, ends_with("D")) |>
    rename(area_name = Area_name) |>   
    pivot_longer(cols = ends_with("D"),
                 names_to = "code",
                 values_to = default_var_name)
  return(tmp)
}
```

In the third step to the data processing section above, we looked at parsing strings, specifically breaking up the census code into the survey type and survey year. We again put the process we followed into a single function `function_for_step_3` that takes as input the output from `function_for_step_1_2`. Note that we must have renamed the census codes to `code` upon reshaping the data in `function_for_step_1_2` for this to work. 


```{r}
function_for_step_3=function(mytibble) {
  survey_type=str_sub(mytibble$code, start=1, end=7)
  yy=as.numeric(str_sub(mytibble$code, start=8, end=9))
  survey_year=as.numeric(ifelse(yy<=10,                        
                                paste0("200", yy),
                                paste0("19", yy)))
  tmp=mytibble |>
    mutate(survey_type=survey_type, survey_year=survey_year) |>
    select(area_name, STCOU, survey_type, survey_year, observed)
  return(tmp)
}
```

Skipping a step, in the fifth step to the data processing section above, we looked at parsing our `area_name` into separate variables for the `state` and `county`. We now put this process into a single function `function_for_step_5`. 

```{r}
function_for_step_5=function(mytibble) {
  tmp=mytibble |> 
    mutate(state=str_sub(area_name, nchar(mytibble$area_name) - 1, nchar(mytibble$area_name)),
           district=str_sub(area_name, 1, nchar(mytibble$area_name)-4)) |>
    select(-area_name) |>
    select(state, district, everything())
  return(tmp)
}
```

In the sixth step to the data processing section above, we looked at adding the division of our `area_name` to the tibble. We now put this process into a single function `function_for_step_6`. 

```{r}
function_for_step_6=function(mytibble) {
  d1=c("CONNECTICUT", "MAINE", "MASSACHUSETTS", "NEW HAMPSHIRE", "RHODE ISLAND", "VERMONT")
  d2=c("NEW JERSEY", "NEW YORK", "PENNSYLVANIA")
  d3=c("ILLINOIS", "INDIANA", "MICHIGAN", "OHIO", "WISCONSIN")
  d4=c("IOWA", "KANSAS", "MINNESOTA", "MISSOURI", "NEBRASKA", "NORTH DAKOTA", "SOUTH DAKOTA")
  d5=c("DELAWARE", "FLORIDA", "GEORGIA", "MARYLAND", "NORTH CAROLINA", "SOUTH CAROLINA", "VIRGINIA", "DISTRICT OF COLUMBIA", "District of Columbia", "WEST VIRGINIA")
  d6=c("ALABAMA", "KENTUCKY", "MISSISSIPPI", "TENNESSEE")
  d7=c("ARKANSAS", "LOUISIANA", "OKLAHOMA", "TEXAS")
  d8=c("ARIZONA", "COLORADO", "IDAHO", "MONTANA", "NEVADA", "NEW MEXICO", "UTAH", "WYOMING")
  d9=c("ALASKA", "CALIFORNIA", "HAWAII", "OREGON", "WASHINGTON")
  
  region=list(d1,d2,d3,d4,d5,d6,d7,d8,d9)
  division=vector()
  
  for (i in 1:nrow(mytibble)) {
    j=1
    
    while(j<=length(region) && !(mytibble$area_name[i] %in% region[[j]])) {
      j=j+1
    }
    
    division[i]=ifelse(j<=length(region), j, "ERROR")
  }
  mytibble$division=division
  
  tmp=mytibble |>
    select(area_name, division, everything())
   return(tmp) 
}
```

We now return to our skipped fourth step, breaking the data into county and non-county data. Our function just copies our previous procedure in the data prcessing section, and then applies our `function_for_step_5` and `function_for_step_6` to the split data. We return a list whose first element is our `county` tibble and whose second element is our `noncounty` tibble.

```{r}
function_for_step_4_5_6=function(mytibble) {
  a=str_locate(mytibble$area_name, ",")[,1]            
  noncounty=mytibble[which(is.na(a)),]                 
  county=mytibble[which(!is.na(a)),]
  
  class(county)=c("county", class(county))           
  class(noncounty)=c("state", class(noncounty))      
  
  county=function_for_step_5(county)
  noncounty=function_for_step_6(noncounty)
  
  return(list(county,noncounty))
}
```

Finally, we create a single wrapper function that brings all of the above functions together.

```{r}
myfunction=function(url, default_var_name="observed") {
  result=function_for_step_1_2(url, default_var_name) |>
    function_for_step_3()|>
    function_for_step_4_5_6()
  
  return(result)
}
```

We check that this performs as expected by comparing it's output to the values we already computed. Using the `all.equal` function, we see that it does!

```{r}
test=myfunction("https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv")
all.equal(test[[1]], county)
all.equal(test[[2]], noncounty)
rm(test)
```

With this function now in hand, we read in both the old data source and a new one accessible at [https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv](https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv).

```{r}
file1="https://www4.stat.ncsu.edu/~online/datasets/EDU01a.csv"
file2="https://www4.stat.ncsu.edu/~online/datasets/EDU01b.csv"

tibble1=myfunction(file1)
tibble2=myfunction(file2)
```

We then write a function to combine like data with like data (i.e. the county data from the first data source is combined with the county data from the second data source). We use the base function `rbind()` to do so, though we could also use the `dplyr` function `bind_rows()`.

```{r}
function_combine=function(mytib1, mytib2) {
  county_data=rbind(mytib1[[1]],mytib2[[1]])
  non_county_data=rbind(mytib1[[2]], mytib2[[2]])
  return(list(county_data, non_county_data))
}

combined_data=function_combine(tibble1,tibble2)
```


## Summarizing With Visuals
We now turn our attention to summarizing our results. We'd like to create functions that utilize the `ggplot2()` package in the `tidyverse` to return nice visuals of our data.

### Mean Enrollemnt By Division
Our first function will summarize non-county data, returning the mean enrollment value by year for each division that the respective state is in. We only care about divisions, so exclude any values in our data that  aren't part of one by using `filter`. We want to plot our data for each division by year, so we use `group_by()` to do so. Finally, we want to find the mean value of each division each year, which we can grab with the `summarize()` function. We then plot this object using `ggplot()`, making small adjustments to make the output more visually appealing (such as centering the title with `theme(plot.title = element_text(hjust = 0.5))` and removing `ggplots()` ugly default with ` theme_bw()`). 

```{r}
plot.state=function(mytibble, default_var_name="observed") {
  tmp=mytibble |>
    filter(division != "ERROR") |>
    group_by(division, survey_year) |>
    summarize(mean_observed=mean(mean(get(default_var_name))))
  
  ggplot(tmp, aes(x=survey_year, y=mean_observed, color=division)) +
    geom_line() +
    labs(x="Year", 
         y="Mean Enrollemnt Value", 
         color="Division", 
         title = "Mean Enrollment Value by Year and Division") +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5))
}
```

To make sure the function works as expected, we pass in the output from our `combined_data()`.

```{r}
plot.state(combined_data[[2]])
```
